{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Lab3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALMerrill/cs474_labs_f2019/blob/master/DL_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6Q2237c4yK",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALMerrill/cs474_labs_f2019/blob/master/DL_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Lab 3: Intro to CNNs and DNNs\n",
        "\n",
        "## Objectives\n",
        "\n",
        "* Build and train a deep conv net\n",
        "* Explore and implement various initialization techniques\n",
        "* Implement a parameterized module in Pytorch\n",
        "* Use a principled loss function\n",
        "\n",
        "## Video Tutorial\n",
        "[https://youtu.be/3TAuTcx-VCc](https://youtu.be/3TAuTcx-VCc)\n",
        "\n",
        "## Deliverable\n",
        "For this lab, you will submit an ipython notebook via learningsuite.\n",
        "This is where you build your first deep neural network!\n",
        "\n",
        "For this lab, we'll be combining several different concepts that we've covered during class,\n",
        "including new layer types, initialization strategies, and an understanding of convolutions.\n",
        "\n",
        "## Grading Standards:\n",
        "* 30% Part 0: Successfully followed lab video and typed in code\n",
        "* 20% Part 1: Re-implement Conv2D and CrossEntropy loss function\n",
        "* 20% Part 2: Implement different initialization strategies\n",
        "* 10% Part 3: Print parameters, plot train/test accuracy\n",
        "* 10% Part 4: Convolution parameters quiz\n",
        "* 10% Tidy and legible figures, including labeled axes where appropriate\n",
        "___\n",
        "\n",
        "### Part 0\n",
        "Watch and follow video tutorial:\n",
        "\n",
        "[https://youtu.be/3TAuTcx-VCc](https://youtu.be/3TAuTcx-VCc)\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Watch tutorial\n",
        "\n",
        "**DONE:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "HNAUhHI0c4yR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wQOefmcZVgTl",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "\n",
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QY4owfQwm-Ni"
      },
      "source": [
        "___\n",
        "\n",
        "### Part 1\n",
        "Re-implement a Conv2D module with parameters and a CrossEntropy loss function.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* CrossEntropyLoss \n",
        "* Conv2D\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Conv2D\n",
        "___\n",
        "\n",
        "### Part 2\n",
        "Implement a few initialization strategies which can include Xe initialization\n",
        "(sometimes called Xavier), Orthogonal initialization, and uniform random.\n",
        "You can specify which strategy you want to use with a parameter. \n",
        "\n",
        "\n",
        "\n",
        "Helpful links include:\n",
        "*  [Orthogonal Initialization](https://hjweide.github.io/orthogonal-initialization-in-convolutional-layers) (or the original paper: http://arxiv.org/abs/1312.6120)\n",
        "*  http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization\n",
        "\n",
        "**TODO:**\n",
        "* Parameterize custom Conv2D for different initilization strategies\n",
        "* Xe\n",
        "* Orthogonal\n",
        "* Uniform\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RkieTbwlYWPS",
        "colab": {}
      },
      "source": [
        "def Xe(data):\n",
        "  mu = 0\n",
        "  sigma = 1 / len(data[0])\n",
        "  np.random.normal(mu, sigma, (data.size()))\n",
        "  \n",
        "\n",
        "def orthogonal(data):\n",
        "  pass\n",
        "#See Jacob's post in #lab3 for a note on this\n",
        "\n",
        "def uniform(data):\n",
        "  if len(data.size()) > 1:\n",
        "    data.uniform_(-1, 1)\n",
        "  else:\n",
        "    data.uniform_(0,0)\n",
        "  \n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, n_channels, out_channels, kernel_size, stride=1, \n",
        "               padding=0, dilation=1, groups=1, \n",
        "               bias=True, initialization=uniform):\n",
        "    self.__dict__.update(locals())\n",
        "    super(Conv2d, self).__init__()\n",
        "    \n",
        "    self.weight = Parameter(torch.Tensor(out_channels, \n",
        "                               n_channels,\n",
        "                               *kernel_size))\n",
        "    initialization(self.weight.data)\n",
        "    \n",
        "    self.bias = Parameter(torch.Tensor(out_channels))\n",
        "    initialization(self.bias.data)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return F.conv2d(x, self.weight, self.bias, self.stride, \n",
        "                    self.padding, self.dilation, self.groups)\n",
        "  \n",
        "# def oneHotEncode(y):\n",
        "#   y = y.cpu().detach().numpy()\n",
        "#   y_onehot = np.zeros((y.size(0), 10))\n",
        "#   y_onehot[np.arange(y.shape[0]).astype(int), y] = 1\n",
        "\n",
        "class CrossEntropyLoss(nn.Module):\n",
        "  def __init__(self, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='elementwise_mean'):\n",
        "    super(CrossEntropyLoss, self).__init__()\n",
        "  \n",
        "#   def forward(self, y_hat, y_truth):\n",
        "#     sm = nn.Softmax(dim=1)\n",
        "#     y_hat_sftmx = sm(y_hat)\n",
        "#     n, classes = y_hat.size()\n",
        "#     mask = torch.zeros((n, classes))\n",
        "#     mask[np.arange(n), y_truth] = 1\n",
        "#     print(mask.cuda())\n",
        "#     print(y_hat_sftmx)\n",
        "#     print(torch.log(y_hat_sftmx))\n",
        "#     return -torch.sum(mask.cuda() * torch.log(y_hat_sftmx))\n",
        "\n",
        "  def forward(self, y_hat, y_truth):\n",
        "#     maxes, _ = torch.max(y_hat, 1, keepdim=True)\n",
        "#     y_hat = y_hat - maxes\n",
        "#     y_hat = torch.exp(y_hat)\n",
        "#     y_hat = y_hat / torch.sum(y_hat, 1, keepdim=True)\n",
        "    wrong_class_penalty = torch.log(torch.sum(torch.exp(y_hat), dim=1))\n",
        "#     print(\"start\")\n",
        "#     print(y_hat)\n",
        "#     print(torch.exp(y_hat))\n",
        "#     print(torch.sum(torch.exp(y_hat), dim=1))\n",
        "#     print(wrong_class_penalty)\n",
        "    n, classes = y_hat.size()\n",
        "    mask = torch.zeros((n,classes))\n",
        "    mask[np.arange(n), y_truth] = 1\n",
        "    true_class_preds = torch.sum(y_hat * mask.cuda(), dim=1)\n",
        "    return torch.mean(-true_class_preds + wrong_class_penalty)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPibEq4SdRhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self, dataset):\n",
        "    super(ConvNetwork, self).__init__()\n",
        "    x, y = dataset[0]\n",
        "    c, h, w = x.size()\n",
        "    output = 10\n",
        "    dim1 = 50\n",
        "    dim2 = 25\n",
        "    dim3 = 40\n",
        "    image_size = (28,28)\n",
        "    initial = uniform\n",
        "    self.net = nn.Sequential(\n",
        "        Conv2d(c, dim1, (3,3), padding=(1,1), initialization=initial),\n",
        "        nn.ReLU(),\n",
        "        Conv2d(dim1, dim2, (3,3), padding=(1,1), initialization=initial),\n",
        "        nn.ReLU(),\n",
        "        Conv2d(dim2, dim3, (3,3), padding=(1,1), initialization=initial),\n",
        "        nn.ReLU(),\n",
        "        Conv2d(dim3, output, (28,28), padding=(0,0), initialization=initial)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x).squeeze(2).squeeze(2)\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "  \n",
        "  \n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "  def __init__(self, root, train=True):\n",
        "    self.data = datasets.FashionMNIST(root, \n",
        "                                      train=train, \n",
        "                                      transform=transform, \n",
        "                                      download=True)\n",
        "    \n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.data[i]\n",
        "    return x, y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "id": "uziQ6wWhdBk-",
        "colab": {}
      },
      "source": [
        "  \n",
        "train_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=True)\n",
        "val_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=False)\n",
        "model = ConvNetwork(train_dataset)\n",
        "model = model.cuda()\n",
        "objective = CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                       batch_size=batch_size,\n",
        "                       pin_memory=True)\n",
        "\n",
        "data_loaders = {'train': train_loader, 'val': val_loader}\n",
        "\n",
        "losses = []\n",
        "validations = []\n",
        "train_acc = []\n",
        "val_acc = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr2xYrNldiQH",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "id": "XAGmnKZfdBWz",
        "outputId": "ffd62808-705d-44d4-fddb-d34861050433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EPOCHS = 1\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "  \n",
        "  for batch, (x, y_truth) in enumerate(train_loader):\n",
        "    x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "    optimizer.zero_grad()\n",
        "    y_hat = model(x)\n",
        "    \n",
        "    loss = objective(y_hat, y_truth)\n",
        "    print('loss:', loss)\n",
        "    loss.backward()\n",
        "    \n",
        "    losses.append(loss.item())\n",
        "    acc = (y_hat.argmax(1) == y_truth).float().mean()\n",
        "    train_acc.append(acc)\n",
        "    #### Just plot the accuracy of each batch? Or running accuracy? Or something else?\n",
        "    \n",
        "    \n",
        "    loop.set_description('epoch: {}, loss: {:.4f}, accuracy: {:.3f}'\n",
        "                         .format(epoch, loss, acc))\n",
        "    loop.update(1)\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch % 100 == 0:\n",
        "\n",
        "      y_hat_val = np.mean([(model(x.cuda()).argmax(1) == y_truth.cuda()).float().mean().item() for x, y_truth in val_loader])\n",
        "      val_acc.append((len(losses), y_hat_val))\n",
        "      val = np.mean([objective(model(x.cuda()), y.cuda()).item() \n",
        "                     for x, y in val_loader])\n",
        "      validations.append((len(losses), val))\n",
        "  loop.close()\n",
        "  \n",
        "a, b = zip(*validations)\n",
        "plt.plot(losses, label='train')\n",
        "plt.plot(a,b, label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 6198.1396, accuracy: 0.000:   0%|          | 0/60000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: tensor(6198.1396, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6e6msC6FJIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c75ad001-d2ee-4fbd-e4fd-10d3ada47d04"
      },
      "source": [
        "a, b = zip(*val_acc)\n",
        "plt.plot(a,b, label='val')\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X9w1fWd7/HnOz/IDwgQIBAkgaAi\niqCoiKi9q21tBa3QW6titbozvWX2Xl1td7d76eyO2/V27nT3znR3O+PerdvrLFhbdLVuaQularXd\nLkEB648AKsgmJPxKCIQfJiG/3veP8004xEAO4STnfM55PWaYnPM9X07eX4wv3ny+3/N9m7sjIiKZ\nJSfVBYiISPIp3EVEMpDCXUQkAyncRUQykMJdRCQDKdxFRDKQwl1EJAMp3EVEMpDCXUQkA+Wl6htP\nmjTJq6qqUvXtRUSCtHXr1kPuXjbYfikL96qqKrZs2ZKqby8iEiQzq0tkPy3LiIhkIIW7iEgGUriL\niGQghbuISAZSuIuIZCCFu4hIBlK4i4hkoDDDvbsLtq6CPZvg1f8NJ4+nuiIRkbSSsg8xnZcdP4Wf\nPQIF4+DkUbjuj1JdkYhIWgkz3POKYl9PHo19LShJXS0ick7cndaObo61d3KsrYvO7h5yzMjJIfbV\ner/GfplBTo6RG71m/ffJ4fR9o9dzcwwzS/XhpkyY4W5xq0m5BZCbn7paRLJQR1dPFM6dHGvv4mhb\n7PHRts6+0D71+OP7dfX4iNV6Ln8RJLJv/9d7f19u/31z4v+SOn3f+xbN4KZLBr09zHkJM9x7Ok89\nLhiTujpEAtXT45zo6OJoa2Jh3D+02zq7z/r+o3JzGFuUz9iiPMYW5jO+eBTTJ45mXPR8XFF+7PXC\nfPJzjR6PdfQ9Dt3u0WOnpwd63PFoe0+0j7vT0+N09/2+2Pa+fXv67etOd0/i+/Z47M8o4X371dvd\n43R0D7Bv9Prx9s6z/vklQ5jh3t1x6vEohbtkH3fnZFfPacEbC+Ku2OPWAbb17tfayfGTXfhZmmcz\nKCnIY1xxLIDHFuZz4aQxjC3KiwVzYSycx0UB3n9bQV5OVi+JpINAwz3ub728wtTVIZIEPT1O04mT\n1B9u5eCxk33d86nQ7oo66biwbuuko7vnrO9blJ/b1zmPK8pnythCLplSwtjCvFPBHAVy/4AuKcgj\nJ0fhHLLww93P/s9DkVRzdw5/1EHDkTbqj7RSfzj2teFIGw2HW2loaaOj6+NBnZtjjC3M61vCGFeU\nzwXjimKBHQVx/GvxoV1SmEdBXm4KjlbSRaDhHrcs09OVujpEIsfaO6k/HAvuhii46w+39gV6a8fp\nTcj44nwqS4uZXV7CLXOmUFlaREVpMeXjChkXBXTxqFwtbciQBRrucZ17t8Jdhl9rR1es0+7tvOOC\nu/5wK8faT/85HD0ql8oJxVROKOaGiydSUVpMZWkRlROKqSgtoqRQV3jJ8Aoz3OOvllHnLklwsqub\nfS3tse47rvOuP9LG3iOtHDrRcdr+BXk5VERhfdX08VSWFvcFd2VpMeOL89V1S0qFGe5alpFz1NXd\nw/6j7X3ddsNpnXcbB4+3n3b1SF6OMa20iIrSIm65bEpfcFeUFlM5oYiyMQUKb0lrgYZ7XKAr3IXT\nrziJhfep4G5oaWVfSzvdcR+cMYOpYwupmFDMjRdP6uvCK0uLqJhQTPnYQnJ1tYgELKFwN7PFwD8A\nucAP3P07/V7/O+CT0dNiYLK7j09moaeJ79yvun/Yvo2kj94rTurj170HueKkrKSAitIirqosZemV\nseWS3s576rgiRuWFed88kUQMGu5mlgs8AXwGaAA2m9lad9/eu4+7fz1u/z8GrhqGWk/p7ohd3/7n\nu0/dZ0Yyxsmubn638xC/23WIPc2n1sDPdMXJpVPjrjjp7b5LiynM16WAkr0S6dwXArvcfTeAma0B\nlgHbz7D/vcBfJae8M+jpgtxRMGr0sH4bGTmtHV385v0m1tcc4NfvNXLiZBdF+bnMmFjM9AmjufHi\nSVHnrStORBKRSLhPA+rjnjcA1w20o5nNAGYCvz7D6yuAFQDTp08/p0JP092hm4VlgOPtnfz6vUbW\nv3uA1z5opL2zhwmjR/G5K6ayeG45N1w0SUsnIkOU7BOqy4Hn3Qf+2Ki7Pwk8CbBgwYKh3xauuwNy\nFO4hOvJRBy/tOMgvaw7wu52H6OjuYXJJAXddU8mSueUsnDmBvFwFusj5SiTc9wKVcc8rom0DWQ48\ndL5FDao7WpaRIDQdP8mGbQf4Zc0Bqnc3093jTBtfxJevn8GSueVcPb1U9zERSbJEwn0zMMvMZhIL\n9eXAl/rvZGaXAqVAdVIrHIiWZdLevpY2flkTC/TNdYdxh5mTRrPiDy5kydxy5k0bp+vERYbRoOHu\n7l1m9jCwgdilkE+5+zYzexzY4u5ro12XA2vcz3Yj0SRRuKelPc2trK/Zz7qaA7xd3wLA7CklPPKp\nWSyZV87sKSUKdJERktCau7uvA9b12/ZYv+ffSl5Zg+jpUriniV2Nx1n/7gHW1xxg+/5jAMybNo5v\n3DqbJXPLubBM99sXSYVAP6HaoTX3FHF3tu8/xi9rYoG+q/EEANfMKOUvb7+MWy8vp3JCcYqrFJFw\nw11Xy4wYd+et+pa+QN9zuJUcg+tmTuSB62dw6+XlTBmroSki6STQcNeyzHDr7nG21B5mfc0BNmw7\nwP6j7eTnGjdcNIn/cfNFfGbOFCaOKUh1mSJyBoGGewfkj0t1FRmns7uHTbubWV9zgF9tO8ihEycZ\nlZfDTZeU8Y1bZ/Ppy6Ywrkh/qYqEINxwV+eeFL33cVlfc4CXdxykpbWT4lG5fHL2ZBbPLeeTl05m\nTEGYPyYi2SzM/2t1tcx5aevo5jcfNLK+5gCv7Ijdx6WkMI9bLpvC4rnl3HRJmW66JRK4MMNdJ1TP\nWe99XH5Zc4DX3m+irbOb0uJ8bp83lcXzyrlR93ERyShhhrv3gCmIBtPS2sFL22P3cfn3uPu4fPGa\nCt3HRSTDBRruHhulIx/TdPwkv9oe3cflw2a6dB8XkawUZrjjgAKq1/6jbX3XoG+uPXUfl6/qPi4i\nWSvMcFfn3ncfl/U1B3gruo/LJVPG6D4uIgKEGu5ANnbuA93HZe60sXzj1tksnlvORbqPi4hEAg33\n4b/xZDo5cbKL+3/wel+HfvX08fzFbZexeK7u4yIiAwsz3J2sWpZ58c0G3qpv4c8Xz+YLV1VQPk73\ncRGRswsz3LPohKq7s6q6jisqxvHfb7pI6+gikpAwL3LOohOq1bub2dV4gi8vmqFgF5GEhRnuWdS5\nr95YR2lxPndceUGqSxGRgIQZ7u5Zke17W9r41fYD3HPtdN3rRUTOSZjhniWd+49erwPgvuump7gS\nEQlNmOGeBWvu7Z3d/PiNej592RRd7igi5yzMcM+Czn3du/s5/FEHD15flepSRCRACYW7mS02s/fN\nbJeZrTzDPneb2XYz22ZmP0pumf1kQee+qrqOC8tGc+PFE1NdiogEaNDr3M0sF3gC+AzQAGw2s7Xu\nvj1un1nAN4Eb3f2ImU0eroJjMrtzf7u+hbfrW/jWHXN0+aOIDEkinftCYJe773b3DmANsKzfPl8F\nnnD3IwDu3pjcMgeQwaG3urqO0aNyufOailSXIiKBSiTcpwH1cc8bom3xLgEuMbP/MLNNZrY4WQUO\nyDP33jLNJ07ys3f28YWrKygp1LQpERmaZN1+IA+YBdwMVAC/NbN57t4Sv5OZrQBWAEyffj6X92Xu\nssyzW+rp6OrhgetnpLoUEQlYIp37XqAy7nlFtC1eA7DW3Tvd/T+BD4iF/Wnc/Ul3X+DuC8rKyoZa\nc8aeUO3q7uGZTXu44aKJzJpSkupyRCRgiYT7ZmCWmc00s1HAcmBtv33+jVjXjplNIrZMszuJdfaT\nmZ37K+81sreljQd0+aOInKdBw93du4CHgQ3ADuA5d99mZo+b2dJotw1As5ltB14FvuHuzcNVdKZ2\n7k9X13HBuEJuuWyYLzYSkYyX0Jq7u68D1vXb9ljcYwf+JPo1AjKvc9/VeJzf7TrEN26dTV5uoJ8t\nE5G0EWaKZOCwjqer6xiVm8M911YOvrOIyCDCDPcM69yPt3fy/NYGPnfFVCaNKUh1OSKSAcIM9wxb\nc3/x93v5qKObB26oSnUpIpIhwgz3DOrc3Z1VG2u5smIc8yvHp7ocEckQYYZ7BnXuGz9s5sOmj3T5\no4gkVZjhnkFWV9cyYfQobr9iaqpLEZEMEmi4Z8a9Zfa2tPHS9oPcc22lxuiJSFKFGe4ZsizzzCaN\n0ROR4RFmuGfACdX2zm7WbK7nlsumUFGqMXoiklxhhnsGdO6/eCcao6fLH0VkGIQZ7hnQua+uruWi\nstHccJHG6IlI8oUZ7oF37m/Vt/B2w1EeuL5KY/REZFiEGe6Bd+6rq2sZPSqXL1zdf6CViEhyhBnu\nAXfuzSdO8vO393PnNRqjJyLDJ8xwD7hzX7O5no5ujdETkeEVZrgH2rnHxujVcePFE7l4ssboicjw\nCTPcA+3cX97RyL6j7bqPjIgMu0DDnSA799XVtVwwrpBPX6oxeiIyvMIN98DsajzOxg+buW/RDI3R\nE5FhF17KeO9Nw8Lq3FdHY/SWa4yeiIyAcMM9oGWZ4+2dvLC1gc9dOZWJGqMnIiMgvHAnvM79J2/G\nxug9qBOpIjJCEgp3M1tsZu+b2S4zWznA639oZk1m9lb0678lv9RIYJ27u7OqupYrK8dzpcboicgI\nyRtsBzPLBZ4APgM0AJvNbK27b++367Pu/vAw1NhPWJ37f+xqZnfTR3z37itTXYqIZJFEOveFwC53\n3+3uHcAaYNnwlnUWfZ17yio4J71j9G6bpzF6IjJyEgn3aUB93POGaFt/d5rZO2b2vJkNeEmIma0w\nsy1mtqWpqWkI5UJInXvDkVZe3nGQ5RqjJyIjLFknVH8GVLn7FcBLwKqBdnL3J919gbsvKCsrG9p3\nCmjN/ZnX9wBw3yLdR0ZERlYi4b4XiO/EK6Jtfdy92d1PRk9/AFyTnPIGEkbn3t7ZzZo39vCZOVOY\nNr4o1eWISJZJJNw3A7PMbKaZjQKWA2vjdzCz+AXlpcCO5JXYTyCd+8/f2c+R1k5d/igiKTHo1TLu\n3mVmDwMbgFzgKXffZmaPA1vcfS3wiJktBbqAw8AfDl/J6d+5uzurNtZy8eQxXK8xeiKSAoOGO4C7\nrwPW9dv2WNzjbwLfTG5p4XqrvoV39x7l8WWXa4yeiKREeJ9QDWBZ5unqOsYU5PGFqytSXYqIZKnw\nwj3Nl2UOnTjJz9/Zz51XT2NMQUL/MBIRSbrwwj3NO/dnozF6X9aJVBFJofDCPY07967uHn64qY5P\nXDyJiyePSXU5IpLFwgv3NO7cX95xkP1H2zX8WkRSLrxwT+POfdXGOqaNL+LTl01JdSkikuXCC/c0\n7dx3HjxO9e5m7ls0ndyc9KpNRLJPeOHeJ70CdHV1HaPycrhngcboiUjqhRfuadi5H2vv5IU3G7jj\nigs0Rk9E0kJ44Z6Ga+4/2dpAa0c3D96gE6kikh7CC/c069x7epzV1XXMrxzPFRUaoyci6SG8cE8z\n//HhIXYf+khdu4iklQDD3QffZQStrq5josboiUiaCS/c02hZpv5wK6/sOMjyhZUU5GmMnoikj/DC\nPY1OqPaN0btOSzIikl7CC/c06dzbO7t5dvMePjunnAs0Rk9E0kx44Z4mnfvP3t7HkdZOHtCJVBFJ\nQ+GFexp07u7OqupaZk0ew/UXaoyeiKSf8MI9DTr339e3ULP3GA/cUKUxeiKSlsIL9zTo3HvH6P3X\nq6alrAYRkbMJL9xT3Lk3HT/JL97ZzxevqdAYPRFJWwmFu5ktNrP3zWyXma08y353mpmb2YLkldhP\nijv3ZzfvoaO7h/sX6USqiKSvQcPdzHKBJ4AlwBzgXjObM8B+JcCjwOvJLvJ0qevcY2P09vBfZmmM\nnoikt0Q694XALnff7e4dwBpg2QD7/S/gb4D2JNZ3Zino3F/afpADx9p5QMOvRSTNJRLu04D6uOcN\n0bY+ZnY1UOnuv0hibQPz1N1bZlV1LdPGF/GpSyenrAYRkUSc9wlVM8sBvgv8aQL7rjCzLWa2pamp\naYjfMTXLMh8cPM6m3Ye5f9EMjdETkbSXSLjvBeJnx1VE23qVAHOB18ysFlgErB3opKq7P+nuC9x9\nQVlZ2dAqTtEJ1dXVtbExetdqjJ6IpL9Ewn0zMMvMZprZKGA5sLb3RXc/6u6T3L3K3auATcBSd98y\nLBX3GblwP9beyU/e3MvSKy9gwuhRI/Z9RUSGatBwd/cu4GFgA7ADeM7dt5nZ42a2dLgLHKCg2NcR\n7Nxf6B2jpxOpIhKIhD6F4+7rgHX9tj12hn1vPv+yzlpN9HVkwr2nx3m6uo6rpo9nXsW4EfmeIiLn\nK7xPqI5w5/67XdEYPXXtIhKQ8MJ9hMfsra6uZdKYUSyZVz6i31dE5HyEF+4j2LnXH27llfcaWX7t\ndI3RE5GghBfuI7jm/sPX68gx40vXTR/27yUikkzhhfsIde6xMXr1fHbOFI3RE5HghBfufYY33Ne+\nvY+W1k7dR0ZEghRguA//CVV3Z9XGWi6ZMoZFF04Y9u8nIpJs4YX7CCzLvLmnhW37jvHA9RqjJyJh\nCi/cR+CE6tPVtZRojJ6IBCy8cB/mzr3p+El+8e5+7rymgtEaoycigQov3Ie5c1/zxh46u50vX68x\neiISrvDCfRg7987uHp55PTZG76IyjdETkXCFF+7D2Ln3jtHTfWREJHThhfswdu6rNtZSUVrEJzVG\nT0QCF164D1Pn/t6BY7z+n4f5ssboiUgGCC/c+7I9uQH8dHUdBXk53L1AY/REJHzhhfswdO5H206N\n0SvVGD0RyQABhnskiZ37C1sbaOvs5sEbqpL2niIiqRReuHty7y3T0+M8vamOq6ePZ+40jdETkcwQ\nXrgneVnm33cd4j8PfaSuXUQySnjh3ncpZHLebvXGWiaNKWDJ3KnJeUMRkTSQULib2WIze9/MdpnZ\nygFe/yMze9fM3jKz35nZnOSX2it5nXv94VZ+/X4j9y6sZFReeH/PiYicyaCJZma5wBPAEmAOcO8A\n4f0jd5/n7vOBvwW+m/RKeyXxQ0w/3KQxeiKSmRJpVxcCu9x9t7t3AGuAZfE7uPuxuKejGdaJGsnp\n3Ns6ulmzuZ5bL5/C1HEaoycimSWRe9pOA+rjnjcA1/XfycweAv4EGAV8KinVDSRJnfvP3t7H0TaN\n0RORzJS0hWZ3f8LdLwL+J/CXA+1jZivMbIuZbWlqahrqd+p9tyH+/tgYvX/ZWMvsKSVcN1Nj9EQk\n8yQS7nuB+M/kV0TbzmQN8PmBXnD3J919gbsvKCsrS7zK098k9vU8Ovc39xxh+/5jPHDDDI3RE5GM\nlEi4bwZmmdlMMxsFLAfWxu9gZrPint4O7Exeif2df+e+amMdJYV5fH6+xuiJSGYadM3d3bvM7GFg\nA5ALPOXu28zscWCLu68FHjazW4BO4Ajw4LBVfJ6de+PxdtbX7Of+RTM0Rk9EMlZC6ebu64B1/bY9\nFvf40STXlYChhfuaN+pjY/QWaYyeiGSuAD+5M/SrLGNj9Or4g0vKuFBj9EQkg4UX7uexLPOrbQc5\neOwkD2r4tYhkuPDC/TxOqK6qrqVyQhE3z9YYPRHJbOGF+xA79/cOHOMNjdETkSwRXrgPsXNfrTF6\nIpJFwgv3IcxQPdrWyYtv7mXZ/AsYX6wxeiKS+cIL9yF07s9HY/R0HxkRyRbhhfs5rrn39DhPV9dy\nzYxSjdETkawRXrifY+f+251N1Da38oAufxSRLBJeuJ/jmL3V1XUaoyciWSe8cD+Hzn1Pcyuvvt/I\nl66brjF6IpJVwku8c1hz/+Hr0Ri9hRqjJyLZJbxwT1BbRzfPbq5n8eXllI8rTHU5IiIjKsBwT2xZ\nZu3be6MxejqRKiLZJ7xwT2BZxt1ZtbGOS8tLWKgxeiKShcIL9wQ696110Ri966s0Rk9EslJ44Z5A\n576qOhqjd9UFI1SUiEh6CS/cB+ncG4+1s/7d/dx1TSXFozRGT0SyU3jhPkjn/uM36unqcb6sE6ki\nksXCC/ezdO69Y/RuuqSMmZNGj2xZIiJpJLxwP0vnvmHbARqPn+TBG9S1i0h2Cy/cz9K5r95Yx/QJ\nxdx0icboiUh2SyjczWyxmb1vZrvMbOUAr/+JmW03s3fM7BUzG77W+Qyd+479x3ijVmP0REQggXA3\ns1zgCWAJMAe418zm9Nvt98ACd78CeB7422QXOkBlpz1bXV1HYX4Ody2oGP5vLSKS5hLp3BcCu9x9\nt7t3AGuAZfE7uPur7t4aPd0EDH/CxnXuR1s7+bff72XZldM0Rk9EhMTCfRpQH/e8Idp2Jl8B1p9P\nUWfVuywT51+31tPW2a3LH0VEIkn9lI+Z3Q8sAG46w+srgBUA06cP9Ta8p59Q7elxnt5UxwKN0RMR\n6ZNI574XqIx7XhFtO42Z3QL8BbDU3U8O9Ebu/qS7L3D3BWVlZUOp92MnVH+zs4m65lYeuKFqaO8n\nIpKBEuncNwOzzGwmsVBfDnwpfgczuwr4PrDY3RuTXuVpTl+WWb2xlrKSAhZfXj6831ZE0kJnZycN\nDQ20t7enupRhVVhYSEVFBfn5+UP6/YOGu7t3mdnDwAYgF3jK3beZ2ePAFndfC/wfYAzwr9FdGPe4\n+9IhVTR4QbGvZtQ1f8RrHzTxyKdmaYyeSJZoaGigpKSEqqrMveuru9Pc3ExDQwMzZ84c0nsktObu\n7uuAdf22PRb3+JYhffchObXm/sNNdeSa8aXrNEZPJFu0t7dndLADmBkTJ06kqalpyO8RXrsbde7t\nXc6zm+u5dW45U8ZqjJ5INsnkYO91vscYXrhHnftL2w9yrL2LB6+vSm05IiJnMWbMmJR83/DCPerc\nn39zH5eWl3BtVWmKCxIRST8BTrOIhfvOxhP88ReuzYp/nolI+li5ciWVlZU89NBDAHzrW98iLy+P\nV199lSNHjtDZ2cm3v/1tli1bNsg7Da/wwj3q3EcX5rFsvsboiWSzv/7ZNrbvO5bU95xzwVj+6o7L\nz/j6Pffcw9e+9rW+cH/uuefYsGEDjzzyCGPHjuXQoUMsWrSIpUuXprT5DC7cezy2lvS5K6ZpjJ6I\njLirrrqKxsZG9u3bR1NTE6WlpZSXl/P1r3+d3/72t+Tk5LB3714OHjxIeXnqPn8TXDrmWKxzf+iT\nF6W4EhFJtbN12MPprrvu4vnnn+fAgQPcc889PPPMMzQ1NbF161by8/OpqqpK+Yesggv33mWZvNzc\nFBciItnqnnvu4atf/SqHDh3iN7/5Dc899xyTJ08mPz+fV199lbq6ulSXGGC4n2USk4jISLj88ss5\nfvw406ZNY+rUqdx3333ccccdzJs3jwULFnDppZemusQAw/0sM1RFREbKu+++2/d40qRJVFdXD7jf\niRMnRqqk04R3nbs6dxGRQYUX7urcRUQGFV6491G4i4icSXjhrs5dRGRQ4YW71txFRAYVXrircxcR\nGVR44d5vzJ6IyEhqaWnhH//xH8/599122220tLQMQ0UDCzDcI+rcRSQFzhTuXV1dZ/1969atY/z4\n8cNV1seE+yEmEZEUWLlyJR9++CHz588nPz+fwsJCSktLee+99/jggw/4/Oc/T319Pe3t7Tz66KOs\nWLECgKqqKrZs2cKJEydYsmQJn/jEJ9i4cSPTpk3jpz/9KUVFRUmtM7xw1wlVEem1fiUceHfw/c5F\n+TxY8p0zvvyd73yHmpoa3nrrLV577TVuv/12ampq+gZZP/XUU0yYMIG2tjauvfZa7rzzTiZOnHja\ne+zcuZMf//jH/PM//zN33303L7zwAvfff39SDyO8cNcJVRFJIwsXLuwLdoDvfe97vPjiiwDU19ez\nc+fOj4X7zJkzmT9/PgDXXHMNtbW1Sa8roXA3s8XAPwC5wA/c/Tv9Xv8D4O+BK4Dl7v58sgs9RZ27\niETO0mGPlNGjR/c9fu2113j55Zeprq6muLiYm2++ecBb/xYUFPQ9zs3Npa2tLel1DXpC1cxygSeA\nJcAc4F4zm9Nvtz3AHwI/SnaBH6POXURSqKSkhOPHjw/42tGjRyktLaW4uJj33nuPTZs2jXB1pyTS\nuS8Edrn7bgAzWwMsA7b37uDutdFrPcNQYz/q3EUkdSZOnMiNN97I3LlzKSoqYsqUKX2vLV68mH/6\np3/isssuY/bs2SxatChldSYS7tOA+rjnDcB1w1NOAtS5i0iK/ehHAy9SFBQUsH79+gFf611XnzRp\nEjU1NX3b/+zP/izp9cEIX+duZivMbIuZbWlqahram0yaBXM+DznhnQsWERkpiYT7XqAy7nlFtO2c\nufuT7r7A3ReUlZUN5S3g0tvh7lWQVzD4viIiWSqRcN8MzDKzmWY2ClgOrB3eskRE5HwMGu7u3gU8\nDGwAdgDPufs2M3vczJYCmNm1ZtYA3AV838y2DWfRIpLdPAs+qX6+x5jQwrW7rwPW9dv2WNzjzcSW\na0REhlVhYSHNzc1MnDgRy9ALK9yd5uZmCgsLh/weOispIkGpqKigoaGBIV+UEYjCwkIqKobeMyvc\nRSQo+fn5p33cXwYW7i1/RUTkjBTuIiIZSOEuIpKBLFWXFJlZE1A3xN8+CTiUxHJCoGPODtl2zNl2\nvHD+xzzD3Qf9FGjKwv18mNkWd1+Q6jpGko45O2TbMWfb8cLIHbOWZUREMpDCXUQkA4Ua7k+muoAU\n0DFnh2w75mw7XhihYw5yzV1ERM4u1M5dRETOIrhwN7PFZva+me0ys5WpridZzOwpM2s0s5q4bRPM\n7CUz2xl9LY22m5l9L/ozeMfMrk5d5UNjZpVm9qqZbTezbWb2aLQ9k4+50MzeMLO3o2P+62j7TDN7\nPTq2Z6Nba2NmBdHzXdHrVamsf6jMLNfMfm9mP4+eZ/rx1prZu2b2lpltibaN+M91UOGe4LDuUP0L\nsLjftpXAK+4+C3gleg6x458V/VoB/N8RqjGZuoA/dfc5wCLgoei/ZSYf80ngU+5+JTAfWGxmi4C/\nAf7O3S8GjgBfifb/CnAk2v7XUn27AAACp0lEQVR30X4hepTY7cJ7ZfrxAnzS3efHXfI48j/X7h7M\nL+B6YEPc828C30x1XUk8viqgJu75+8DU6PFU4P3o8feBewfaL9RfwE+Bz2TLMQPFwJvE5hEfAvKi\n7X0/48RmKFwfPc6L9rNU136Ox1lBLMw+Bfyc2GT7jD3eqPZaYFK/bSP+cx1U587Aw7qnpaiWkTDF\n3fdHjw8AvWPWM+rPIfrn91XA62T4MUdLFG8BjcBLwIdAi8eG4sDpx9V3zNHrR4GJI1vxeft74M+B\nnuj5RDL7eAEc+JWZbTWzFdG2Ef+51i1/A+HubmYZd2mTmY0BXgC+5u7H4ocvZOIxu3s3MN/MxgMv\nApemuKRhY2afAxrdfauZ3ZzqekbQJ9x9r5lNBl4ys/fiXxypn+vQOvekDesOxEEzmwoQfW2MtmfE\nn4OZ5RML9mfc/SfR5ow+5l7u3gK8SmxZYryZ9TZa8cfVd8zR6+OA5hEu9XzcCCw1s1pgDbGlmX8g\nc48XAHffG31tJPYX+EJS8HMdWrhn27DutcCD0eMHia1L925/IDrTvgg4GvdPviBYrEX/f8AOd/9u\n3EuZfMxlUceOmRURO8ewg1jIfzHarf8x9/5ZfBH4tUcLsyFw92+6e4W7VxH7f/XX7n4fGXq8AGY2\n2sxKeh8DnwVqSMXPdapPPgzhZMVtwAfE1ir/ItX1JPG4fgzsBzqJrbt9hdh64yvATuBlYEK0rxG7\nauhD4F1gQarrH8LxfoLY2uQ7wFvRr9sy/JivAH4fHXMN8Fi0/ULgDWAX8K9AQbS9MHq+K3r9wlQf\nw3kc+83AzzP9eKNjezv6ta03o1Lxc61PqIqIZKDQlmVERCQBCncRkQykcBcRyUAKdxGRDKRwFxHJ\nQAp3EZEMpHAXEclACncRkQz0/wF9yAFq4ZA08QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsVRXrwTgHme",
        "colab_type": "code",
        "outputId": "e11c5490-ec0d-49e6-b4fd-5f482045f047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# model = ConvNetwork(train_dataset)\n",
        "# model.net[0].weight.data.uniform_(-1,1)\n",
        "# model.net[0].weight\n",
        "\n",
        "a = torch.from_numpy(np.random.randn(3,10,1).astype(np.float32))\n",
        "\n",
        "b = torch.exp(a)\n",
        "\n",
        "z = a / b.sum(1, keepdim=True)\n",
        "\n",
        "#indeces wanted from batches (i[0] says it wants the i[o] index from the first batch, and so on)\n",
        "i = y_truth[:3]\n",
        "row = torch.arange(b.size(0)) # tensor([0, 1, 2]\n",
        "col = i # tensor([3, 2, 4]\n",
        "b[row, col].mean()\n",
        "\n",
        "\n",
        "\n",
        "# # first batch\n",
        "# print(b[0])\n",
        "\n",
        "# # first index of each batch\n",
        "# print(b[:,0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3060],\n",
            "        [0.6013],\n",
            "        [2.6325],\n",
            "        [1.4179],\n",
            "        [0.9850],\n",
            "        [7.1304],\n",
            "        [1.7246],\n",
            "        [0.8546],\n",
            "        [0.6553],\n",
            "        [0.2452]])\n",
            "tensor([[0.3060],\n",
            "        [0.2126],\n",
            "        [0.3982]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2]), tensor([3, 2, 4], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ronkEckHiDaU"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 3\n",
        "Print the number of parameters in your network and plot accuracy of your training and validation \n",
        "set over time. You should experiment with some deep networks and see if you can get a network \n",
        "with close to 1,000,000 parameters.\n",
        "\n",
        "**TODO:**\n",
        "* Experiment with Deep Networks\n",
        "* Plot accuracy of training and validation set over time\n",
        "* Print out number of parameters in the model \n",
        "\n",
        "**DONE:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PaWCKjxvyRSf",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "\n",
        "# Go back up and try a few different networks and initialization strategies\n",
        "# Plot loss if you want\n",
        "# Plot accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oijCR-JnyS6V",
        "pycharm": {
          "is_executing": false
        },
        "outputId": "cea2ebec-79bc-4ae5-8132-e10f0062ff9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute and print the number of parameters in the model\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "num_params"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "334425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7hXGRxUQh9gX"
      },
      "source": [
        "___\n",
        "\n",
        "### Part 4\n",
        "Learn about how convolution layers affect the shape of outputs, and answer the following quiz questions. Include these in a new markdown cell in your jupyter notebook.\n",
        "\n",
        "\n",
        "*Using a Kernel size of 3×3 what should the settings of your 2d convolution be that results in the following mappings (first answer given to you)*\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(3, 3), padding=(0, 0))\n",
        "* (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : **(out_channels=22, kernel_size=(3,3), padding=(1, 1))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=65, h=12, w=12) : **(out_channels=65, kernel_size=(3,3), padding=(2, 2))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=7, h=20, w=20) : **(out_channels=7, kernel_size=(3,3), padding=(6, 6))**\n",
        "\n",
        "*Using a Kernel size of 5×5:*)\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : **(out_channels=10, kernel_size=(5, 5), padding=(1, 1))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : **(out_channels=100, kernel_size=(5,5), padding=(2, 2))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : **(out_channels=23, kernel_size=(5,5), padding=(3, 3))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : **(out_channels=5, kernel_size=(5,5), padding=(9, 9))**\n",
        "\n",
        "*Using Kernel size of 5×3:*\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : **(out_channels=10, kernel_size=(5,3), padding=(1, 0))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : **(out_channels=100, kernel_size=(5,3), padding=(2,1))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : **(out_channels=23, kernel_size=(5,3), padding=(3, 2))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : **(out_channels=5, kernel_size=(5,3), padding=(9, 8))**\n",
        "\n",
        "*Determine the kernel that requires the smallest padding size to make the following mappings possible:*\n",
        "\n",
        "* (c=3, h=10, w=10) ⇒ (c=10, h=9, w=7) : **(out_channels=10, kernel_size=(2,4), padding=(0, 0))**\n",
        "* (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : **(out_channels=22, kernel_size=(1,1), padding=(0, 0))**\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Answer all the questions above \n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Answer all the questions above \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XXfG3wClh8an",
        "pycharm": {
          "is_executing": false
        },
        "outputId": "4ac79baa-d1d9-4ca5-df32-e3a6202efafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "# output_dim = input_dim - kernel_size + 1\n",
        "\n",
        "# O = ((I - K + 2P) / s) + 1\n",
        "# output = ((input_dim - kernel_size + 2*padding) / stride) + 1\n",
        "\n",
        "\n",
        "# Write some test code for checking the answers for these problems (example shown in the video)\n",
        "#Example\n",
        "c = nn.Conv2d(3, 10, kernel_size=(3,3), padding=(0,0))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size(), end=\"\\n\\n\")\n",
        "\n",
        "\n",
        "# 3x3 kernels\n",
        "c = nn.Conv2d(3, 22, kernel_size=(3,3), padding=(1,1))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 65, kernel_size=(3,3), padding=(2,2))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 7, kernel_size=(3,3), padding=(6,6))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size(), end=\"\\n\\n\")\n",
        "\n",
        "\n",
        "# 5x5 kernels\n",
        "c = nn.Conv2d(3, 10, kernel_size=(5,5), padding=(1,1))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 100, kernel_size=(5,5), padding=(2,2))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 23, kernel_size=(5,5), padding=(3,3))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 5, kernel_size=(5,5), padding=(9,9))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size(), end=\"\\n\\n\")\n",
        "\n",
        "\n",
        "# 5x3 kernels\n",
        "c = nn.Conv2d(3, 10, kernel_size=(5,3), padding=(1,0))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 100, kernel_size=(5,3), padding=(2,1))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 23, kernel_size=(5,3), padding=(3,2))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 5, kernel_size=(5,3), padding=(9,8))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size(), end=\"\\n\\n\")\n",
        "\n",
        "\n",
        "# Smallest padding size\n",
        "c = nn.Conv2d(3, 10, kernel_size=(2,4), padding=(0,0))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size())\n",
        "\n",
        "c = nn.Conv2d(3, 22, kernel_size=(1,1), padding=(0,0))\n",
        "print(c(torch.zeros(1, 3, 10, 10)).size(), end=\"\\n\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10, 8, 8])\n",
            "\n",
            "torch.Size([1, 22, 10, 10])\n",
            "torch.Size([1, 65, 12, 12])\n",
            "torch.Size([1, 7, 20, 20])\n",
            "\n",
            "torch.Size([1, 10, 8, 8])\n",
            "torch.Size([1, 100, 10, 10])\n",
            "torch.Size([1, 23, 12, 12])\n",
            "torch.Size([1, 5, 24, 24])\n",
            "\n",
            "torch.Size([1, 10, 8, 8])\n",
            "torch.Size([1, 100, 10, 10])\n",
            "torch.Size([1, 23, 12, 12])\n",
            "torch.Size([1, 5, 24, 24])\n",
            "\n",
            "torch.Size([1, 10, 9, 7])\n",
            "torch.Size([1, 22, 10, 10])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4O6mvvSrnTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}