{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "colab_type": "code",
    "id": "SN47jJFI1hVZ",
    "outputId": "0e22c016-7e4d-4152-83e3-c2100fb99670"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install torchvision\n",
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "colab_type": "code",
    "id": "31qzUxLJNswt",
    "outputId": "5f814cb6-dc73-44dd-c10b-7c40c1ad4727"
   },
   "outputs": [],
   "source": [
    "!wget --load-cookies cookies.txt 'https://docs.google.com/uc?export=download&confirm='\"$(wget --save-cookies cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')\"'&id=0B7EVK8r0v71pZjFTYXZWM3FlRnM' -O img_align_celeba.zip\n",
    "!unzip -q img_align_celeba\n",
    "!mkdir test\n",
    "!mv img_align_celeba test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Bf8vftq3OHU3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils, datasets\n",
    "from tqdm import tqdm\n",
    "from torch.nn.parameter import Parameter\n",
    "import pdb\n",
    "import torchvision\n",
    "import os\n",
    "import gzip\n",
    "import tarfile\n",
    "import gc\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.core.ultratb import AutoFormattedTB\n",
    "__ITB__ = AutoFormattedTB(mode = 'Verbose', color_scheme='LightBg', tb_offset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Cziy0mC-Ny2F"
   },
   "outputs": [],
   "source": [
    "class CelebaDataset(Dataset):\n",
    "  def __init__(self, root, size=128, train=True):\n",
    "    super(CelebaDataset, self).__init__()\n",
    "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root) ,transform = transforms.Compose([transforms.Resize((size,size)),transforms.ToTensor()]))\n",
    "    \n",
    "  def __getitem__(self,index):\n",
    "    img = self.dataset_folder[index]\n",
    "#     print(img[0])\n",
    "    return img[0]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzU-ABS9kKrW"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 0: Implement a generator network\n",
    "\n",
    "---\n",
    "\n",
    "One of the advantages of the “Improved WGAN Training” algorithm is that many different kinds of topologies can be used. For this lab, I recommend one of three options:\n",
    "\n",
    "1. The DCGAN architecture, see Fig. 1.\n",
    "2. A ResNet.\n",
    "3. Our reference implementation used 5 layers:\n",
    "> A fully connected layer\n",
    "4 convolution transposed layers, followed by a batch norm layer and relu (except for the final layer)\n",
    "Followed by a sigmoid (The true image is between 0 to 1 and you want your gen img to be between 0 and 1 too).\n",
    "Don't use batch norms unless you want it to take longer\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Create a generator\n",
    "\n",
    "**DONE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rRkWDPHSN4qP"
   },
   "outputs": [],
   "source": [
    "class DCGAN_Generator(nn.Module):\n",
    "  def __init__(self, latent_size):\n",
    "    super(DCGAN_Generator, self).__init__()\n",
    "    self.latent_size = latent_size\n",
    "    # Fractionally strided convolutions\n",
    "    self.net = nn.Sequential(\n",
    "        # Go down by half the number of input feature maps but scale up by 2\n",
    "        nn.Linear(self.latent_size, 16384),\n",
    "        nn.LeakyReLU(.2)\n",
    "    )\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(256, 128, (2, 2), padding=(0, 0), stride=2), # ->128*16*16\n",
    "        nn.LeakyReLU(.2),\n",
    "        nn.ConvTranspose2d(128, 64, (2, 2), padding=(0, 0), stride=2), # ->64*32*32\n",
    "        nn.LeakyReLU(.2),\n",
    "        nn.ConvTranspose2d(64, 32, (2, 2), padding=(0, 0), stride=2), # ->32*64*64\n",
    "        nn.LeakyReLU(.2),\n",
    "        nn.ConvTranspose2d(32, 3, (2, 2), padding=(0, 0), stride=2), # ->3*128*128\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.net(x)\n",
    "    x = x.view(-1, 256, 8, 8)\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzZxrGzRkgCR"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 1: Implement a discriminator network\n",
    "\n",
    "---\n",
    "\n",
    "Again, you are encouraged to use either a DCGAN-like architecture, or a ResNet.\n",
    "\n",
    "Our reference implementation used 4 convolution layers, each followed by a batch norm layer and leaky relu (leak 0.2) No batch norm on the first layer. You can omit the batch norms to make it go faster\n",
    "\n",
    "Note that the discriminator simply outputs a single scalar value. This value should unconstrained (ie, can be positive or negative), so you should not use a relu/sigmoid on the output of your network\n",
    "**TODO:**\n",
    "\n",
    "* Create a discriminator\n",
    "\n",
    "**DONE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qXAkNBGxkhd5"
   },
   "outputs": [],
   "source": [
    "class DCGAN_Critic(nn.Module):\n",
    "  def __init__(self, latent_size):\n",
    "    super(DCGAN_Critic, self).__init__()\n",
    "    self.latent_size = latent_size\n",
    "    # Convolutions\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, (7, 7), padding=(0, 0)), # 3*128*128 -> 32*122*122\n",
    "        nn.LeakyReLU(.2),\n",
    "        nn.Conv2d(32, 64, (7, 7), padding=(0, 0)), # ->64*116*116\n",
    "        nn.LeakyReLU(.2),\n",
    "        nn.Conv2d(64, 128, (7, 7), padding=(0, 0)), # ->128*110*110\n",
    "        nn.LeakyReLU(.2),\n",
    "        nn.Conv2d(128, 256, (7, 7), padding=(0, 0)), # ->256*104*104\n",
    "        nn.LeakyReLU(.2)\n",
    "    )\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(256*104*104, 1)\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    x = x.view(-1,256*104*104)\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dxe8hOgkvJS"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 2: Implement the Improved Wasserstein GAN training algorithm\n",
    "\n",
    "---\n",
    "\n",
    "The implementation of the improved Wasserstein GAN training algorithm (hereafter called “WGAN-GP”) is fairly straightforward, but involves a few new details:\n",
    "\n",
    "Gradient norm penalty. First of all, you must compute the gradient of the output of the discriminator with respect to x-hat. To do this, you should use the [autograd.grad](https://pytorch.org/docs/stable/autograd.html) function.\n",
    "Reuse of variables. Remember that because the discriminator is being called multiple times, you must ensure that you do not create new copies of the variables. Use requires_grad = True for the parameters of the discriminator. An easier way to do this would be to iterate through the discriminator model parameters and set param.requires_grad = True\n",
    "Trainable variables. In the algorithm, two different Adam optimizers are created, one for the generator, and one for the discriminator. You must make sure that each optimizer is only training the proper subset of variables!\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Compute gradient norm penalty of the discriminator using autograd.grad\n",
    "\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "* Don't create copies of variables (use requires_grad=True)\n",
    "* Make sure the two optimizers only optimize their respective variables\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pQK0AzdXl5eJ"
   },
   "outputs": [],
   "source": [
    "# Initialize your generator and discriminator models\n",
    "LATENT_SIZE = 100\n",
    "\n",
    "def randomSample():\n",
    "  return torch.as_tensor(np.random.random((1, LATENT_SIZE))).float()\n",
    "\n",
    "def randomBatch(batch_size):\n",
    "  return torch.as_tensor(np.random.random((batch_size, LATENT_SIZE))).float()\n",
    "\n",
    "gen_model = DCGAN_Generator(LATENT_SIZE).cuda()\n",
    "disc_model = DCGAN_Critic(LATENT_SIZE).cuda()\n",
    "\n",
    "# Initialize separate optimizer for both gen and disc\n",
    "# These parameters should work decently, adjust them to your liking\n",
    "beta1 = 0.5 # 0\n",
    "beta2 = 0.999 # 0.9\n",
    "lambda_val = 10\n",
    "ncritic = 5 # 5\n",
    "learning_rate = 0.0002 # 0.0001\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "disc_optim = optim.Adam(disc_model.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "gen_optim = optim.Adam(gen_model.parameters(), lr=learning_rate, betas=(beta1,beta2))\n",
    "dobjective = nn.MSELoss()\n",
    "gobjective = nn.MSELoss()\n",
    "\n",
    "#initialize your dataset and dataloader\n",
    "dataset = CelebaDataset('test')\n",
    "# dataset[0]\n",
    "BATCH_SIZE = 64\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZn2D2ytlfn1"
   },
   "source": [
    "---\n",
    "\n",
    "##Part 3: Generating the final face images\n",
    "\n",
    "---\n",
    "\n",
    "Your final deliverable is two images. The first should be a set of randomly generated faces. This is as simple as generating random z variables, and then running them through your generator.\n",
    "\n",
    "For the second image, you must pick two random z values, then linearly interpolate between them (using about 8-10 steps). Plot the face corresponding to each interpolated z value.\n",
    "\n",
    "See the beginning of this lab spec for examples of both images.\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Generate random faces\n",
    "* Randomly interpolate between 2 random z values using 8-10 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "xBORcQAHlx5c",
    "outputId": "d4c21f5a-4367-4579-d352-1b02efab8ecb"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid \n",
    "\n",
    "def showMosaic(images):\n",
    "  images = torch.cat(images, dim=0).cpu().detach()\n",
    "  images = make_grid(images, nrow=10).numpy()\n",
    "  plt.figure()\n",
    "  plt.imshow(np.transpose(images, (1,2,0)))\n",
    "\n",
    "def genRandomImages():\n",
    "  return [gen_model(randomSample().cuda()).clone() for _ in range(100)]\n",
    "\n",
    "def genInterpolationImages():\n",
    "  images = []\n",
    "  for i in range(10):\n",
    "    first = randomSample()\n",
    "    second = randomSample()\n",
    "    gen_input = torch.zeros(1, LATENT_SIZE)\n",
    "    for steps in range(10):\n",
    "      for j in range(100):\n",
    "        maxj = max(first[0][j], second[0][j])\n",
    "        minj = min(first[0][j], second[0][j])\n",
    "        diffj = maxj - minj\n",
    "        gen_input[0][j] = minj + diffj*steps/10\n",
    "      images.append(gen_model(gen_input.cuda()).clone())\n",
    "  return images\n",
    "\n",
    "\n",
    "showMosaic(genRandomImages())\n",
    "showMosaic(genInterpolationImages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "rqgg9ZyGN3_t",
    "outputId": "83df89e2-f3f0-4d64-945f-6860429f9056"
   },
   "outputs": [],
   "source": [
    "start_from_scratch = False\n",
    "epochs = 10\n",
    "def scope():\n",
    "  try:\n",
    "    if os.path.isfile(\"gen_model.pt\") and not start_from_scratch:\n",
    "      print(\"Loading Models\")\n",
    "      gen_model.load_state_dict(torch.load(\"gen_model.pt\"))\n",
    "      disc_model.load_state_dict(torch.load(\"disc_model.pt\"))\n",
    "      print(\"Finished Loading Models\")\n",
    "    for e in range(epochs):\n",
    "      for index, true_img in enumerate(data_loader):\n",
    "        if index % 20 == 0:\n",
    "          gc.collect()\n",
    "          print(\"Memory Usage: {}\".format(torch.cuda.memory_allocated(0) / 1e9))\n",
    "        if index % 400 == 0:\n",
    "          print(\"Saving Models\")\n",
    "          torch.save(gen_model.state_dict(), \"gen_model.pt\")\n",
    "          torch.save(disc_model.state_dict(), \"disc_model.pt\")\n",
    "\n",
    "\n",
    "        true_img = true_img.cuda(async=True)\n",
    "        #train discriminator#\n",
    "\n",
    "        #because you want to be able to backprop through the params in discriminator \n",
    "        for p in disc_model.parameters():\n",
    "          p.requires_grad = True\n",
    "\n",
    "        for p in gen_model.parameters():\n",
    "          p.requires_grad = False\n",
    "\n",
    "        for n in range(ncritic):\n",
    "          disc_optim.zero_grad()\n",
    "\n",
    "          # generate noise tensor z\n",
    "          batch = randomBatch(true_img.size()[0]).cuda(async=True) # One batch 100 dimensions\n",
    "          xtilde = gen_model(batch)\n",
    "          xhat = batch_norm_epsilon*true_img + (1-batch_norm_epsilon*xtilde)\n",
    "          # calculate disc loss: you will need autograd.grad\n",
    "          # TODO: The rest of this\n",
    "          xhat_auto = torch.autograd.Variable(xhat, requires_grad=True)\n",
    "          disc_xhat = disc_model(xhat_auto)\n",
    "    #       print(\"xhat {}\".format(xhat_auto.size()))\n",
    "    #       print(\"disc_xhat {}\".format(disc_xhat.size()))\n",
    "          gradients = torch.autograd.grad(disc_xhat, xhat_auto, torch.ones(disc_xhat.size()).cuda())[0]\n",
    "          gradient_penalty = lambda_val*((gradients.norm(2, dim=1) - 1)**2).mean()\n",
    "          disc_fake = disc_model(xtilde)\n",
    "          disc_real = disc_model(true_img)\n",
    "  #         print(\"disc_fake {}\".format(disc_fake.size()))\n",
    "  #         print(\"disc_real {}\".format(disc_real.size()))\n",
    "  #         print(\"gradient_penalty {}\".format(gradient_penalty.size()))\n",
    "          dloss = (disc_fake - disc_real + gradient_penalty).mean()\n",
    "          # call dloss.backward() and disc_optim.step()\n",
    "          dloss.backward()\n",
    "          disc_optim.step()\n",
    "\n",
    "        #train generator#\n",
    "        for p in disc_model.parameters():\n",
    "          p.requires_grad = False\n",
    "\n",
    "        for p in gen_model.parameters():\n",
    "          p.requires_grad = True\n",
    "\n",
    "        gen_optim.zero_grad()\n",
    "\n",
    "        # generate noise tensor z\n",
    "        batch = randomBatch(true_img.size()[0]).cuda(async=True) # One batch 100 dimensions\n",
    "        # calculate loss for gen\n",
    "        gloss = (-disc_model(gen_model(batch))).mean()\n",
    "        # call gloss.backward() and gen_optim.step()\n",
    "        gloss.backward()\n",
    "        gen_optim.step()\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "      \n",
    "\n",
    "scope()\n",
    "showMosaic(genRandomImages())\n",
    "showMosaic(genInterpolationImages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "ochEN8tWxjg3",
    "outputId": "903fba6e-4d91-4a09-e237-cf42159ce43e"
   },
   "outputs": [],
   "source": [
    "showMosaic(genRandomImages())\n",
    "showMosaic(genInterpolationImages())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DL_Lab8.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
