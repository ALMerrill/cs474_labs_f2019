{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cksgAH12XRjV"
   },
   "source": [
    "# Lab 4: Cancer Detection\n",
    "\n",
    "## Description:\n",
    "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
    "\n",
    "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
    "\n",
    "## There are two parts of this lab:\n",
    "###  1.   Wiring up a basic sequence-to-sequence computation graph\n",
    "###  2.   Implementing your own GRU cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2i_QpSsWG4c"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 0: Readings, data loading, and high level training\n",
    "\n",
    "---\n",
    "\n",
    "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
    "\n",
    "* Read the following\n",
    "\n",
    "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)\n",
    "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "l7bdZWxvJrsx",
    "outputId": "f1629005-936c-4244-d58c-b64bc9c0d59b"
   },
   "outputs": [],
   "source": [
    "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
    "! tar -xzf text_files.tar.gz\n",
    "! pip install unidecode\n",
    "! pip install torch\n",
    "\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    " \n",
    "import pdb\n",
    " \n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "TxBeKeNjJ0NQ",
    "outputId": "adc1e200-9e20-4785-b1cd-d5d1800ce6f2"
   },
   "outputs": [],
   "source": [
    "chunk_len = 200\n",
    " \n",
    "def random_chunk():\n",
    "  start_index = random.randint(0, file_len - chunk_len)\n",
    "  end_index = start_index + chunk_len + 1\n",
    "  return file[start_index:end_index]\n",
    "  \n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "On0_WitWJ99e",
    "outputId": "e854deb4-0cb5-4766-817f-8016bcd736c1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "      tensor[c] = all_characters.index(string[c])\n",
    "  return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYJPTLcaYmfI"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 4: Creating your own GRU cell \n",
    "\n",
    "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
    "\n",
    "---\n",
    "\n",
    "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
    "\n",
    "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "* Create a custom GRU cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aavAv50ZKQ-F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class GRU(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers):\n",
    "    super(GRU, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    self.reset_input_layers = []\n",
    "    self.reset_hidden_layers = []\n",
    "    self.forget_input_layers = []\n",
    "    self.forget_hidden_layers = []\n",
    "    self.new_input_layers = []\n",
    "    self.new_hidden_layers = []\n",
    "    self.reset_input_layers.append(nn.Linear(input_size, hidden_size))\n",
    "    self.reset_hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "    self.forget_input_layers.append(nn.Linear(input_size, hidden_size))\n",
    "    self.forget_hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "    self.new_input_layers.append(nn.Linear(input_size, hidden_size))\n",
    "    self.new_hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "    for i in range(num_layers -1):\n",
    "      self.reset_input_layers.append(nn.Linear(input_size, hidden_size))\n",
    "      self.reset_hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "      self.forget_input_layers.append(nn.Linear(input_size, hidden_size))\n",
    "      self.forget_hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "      self.new_input_layers.append(nn.Linear(input_size, hidden_size))\n",
    "      self.new_hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "    for i, layer in enumerate(self.reset_input_layers):\n",
    "      self.add_module(str(i) + \"_reset_in\", layer)\n",
    "    for i, layer in enumerate(self.forget_input_layers):\n",
    "      self.add_module(str(i) + \"_forget_in\", layer)\n",
    "    for i, layer in enumerate(self.new_input_layers):\n",
    "      self.add_module(str(i) + \"_new_in\", layer)\n",
    "    for i, layer in enumerate(self.reset_hidden_layers):\n",
    "      self.add_module(str(i) + \"_reset_hidden\", layer)\n",
    "    for i, layer in enumerate(self.forget_hidden_layers):\n",
    "      self.add_module(str(i) + \"_forget_hidden\", layer)\n",
    "    for i, layer in enumerate(self.new_hidden_layers):\n",
    "      self.add_module(str(i) + \"_new_hidden\", layer)\n",
    "    \n",
    "  \n",
    "  def forward(self, inputs, hidden):\n",
    "    # Each layer does the following:\n",
    "    # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
    "    # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
    "    # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
    "    # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
    "    # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
    "    hiddens = None\n",
    "    inputs = inputs.view(1,self.input_size)\n",
    "    for i in range(self.num_layers):\n",
    "      new_input = self.new_input_layers[i]\n",
    "      new_hidden = self.new_hidden_layers[i]\n",
    "      reset_input = self.reset_input_layers[i]\n",
    "      reset_hidden = self.reset_hidden_layers[i]\n",
    "      forget_input = self.forget_input_layers[i]\n",
    "      forget_hidden = self.forget_hidden_layers[i]\n",
    "      r_t = torch.sigmoid(reset_input(inputs) + reset_hidden(hidden[i]))\n",
    "      z_t = torch.sigmoid(forget_input(inputs) + forget_hidden(hidden[i]))\n",
    "      n_t = torch.tanh(new_input(inputs) + r_t*(new_hidden(hidden[i])))\n",
    "      outputs = (1-z_t)*n_t + z_t*hidden[i]\n",
    "      if hiddens is None:\n",
    "        hiddens = outputs.unsqueeze(0)\n",
    "      else:\n",
    "        hiddens = torch.cat((hiddens, outputs.unsqueeze(0)), dim=0)\n",
    "      inputs = outputs\n",
    "    return outputs, hiddens\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtXdX-B_WiAY"
   },
   "source": [
    "---\n",
    "\n",
    "##  Part 1: Building a sequence to sequence model\n",
    "\n",
    "---\n",
    "\n",
    "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
    "\n",
    "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
    "\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "* Create an RNN class that extends from nn.Module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "d6tNdEnzWj5F"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "    super(RNN, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    # encode using embedding layer\n",
    "    self.encoding = nn.Embedding(input_size, hidden_size) \n",
    "    # set up GRU passing in number of layers parameter (nn.GRU)\n",
    "    self.GRU = GRU(input_size=hidden_size, hidden_size=hidden_size,num_layers=n_layers)\n",
    "    # decode output\n",
    "    self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, input_char, hidden):\n",
    "    # by reviewing the documentation, construct a forward function that properly uses the output\n",
    "    # of the GRU\n",
    "#     print(input_char)\n",
    "    encoded = self.encoding(input_char.unsqueeze(0).view(-1,1))\n",
    "    out, hidden = self.GRU(encoded, hidden)\n",
    "#     print(out.size())\n",
    "    out_decoded = self.out(out.view(-1,self.hidden_size))\n",
    "    # return output and hidden\n",
    "    return out_decoded, hidden\n",
    "\n",
    "  def init_hidden(self):\n",
    "    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hrhXghEPKD-5"
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "  chunk = random_chunk()\n",
    "  inp = char_tensor(chunk[:-1])\n",
    "  target = char_tensor(chunk[1:])\n",
    "  return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZpiGObbBX0Mr"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 2: Sample text and Training information\n",
    "\n",
    "---\n",
    "\n",
    "We now want to be able to train our network, and sample text after training.\n",
    "\n",
    "This function outlines how training a sequence style network goes. \n",
    "\n",
    "**TODO:**\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "* Fill in the pieces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2ALC3Pf8Kbsi"
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "  ## initialize hidden layers, set up gradient and loss \n",
    "    # your code here\n",
    "  ## /\n",
    "  decoder_optimizer.zero_grad()\n",
    "  hidden = decoder.init_hidden()\n",
    "  loss = 0\n",
    "  for c in range(chunk_len):\n",
    "      output, hidden = decoder(inp[c], hidden)# run the forward pass of your rnn with proper input\n",
    "#       print(output.size())\n",
    "#       print(hidden.size())\n",
    "#       print(target.size())\n",
    "      loss += criterion(output, target[c].unsqueeze(0))\n",
    "      \n",
    "  ## calculate backwards loss and step the optimizer (globally)\n",
    "    # your code here\n",
    "  ## /\n",
    "  loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EN06NUu3YRlz"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 3: Sample text and Training information\n",
    "\n",
    "---\n",
    "\n",
    "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
    "\n",
    "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "**DONE:**\n",
    "\n",
    "* Fill out the evaluate function to generate text frome a primed string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "B-bp-OZ1KjNh"
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "  ## initialize hidden variable, initialize other useful variables \n",
    "    # your code here\n",
    "  ## /\n",
    "  hidden = decoder.init_hidden()\n",
    "  prime_input = char_tensor(prime_str)\n",
    "\n",
    "  # Use priming string to \"build up\" hidden state\n",
    "  for p in range(len(prime_str) - 1):\n",
    "      _, hidden = decoder(prime_input[p], hidden)\n",
    "  inp = prime_input[-1]\n",
    "\n",
    "  predicted = []\n",
    "  predicted.extend(prime_input)\n",
    "  \n",
    "  for p in range(predict_len):\n",
    "      output, hidden = decoder(inp, hidden)#run your RNN/decoder forward on the input\n",
    "\n",
    "      # Sample from the network as a multinomial distribution\n",
    "      output_dist = output.data.view(-1).div(temperature).exp()\n",
    "      top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "      ## get character from your list of all characters, add it to your output str sequence, set input\n",
    "      ## for the next pass through the model\n",
    "       # your code here\n",
    "      ## /\n",
    "      inp = top_i #all_characters[top_i]\n",
    "      \n",
    "      predicted.append(inp)\n",
    "      \n",
    "  predicted = [all_characters[i] for i in predicted]\n",
    "  return ''.join(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Du4AGA8PcFEW"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 4: (Create a GRU cell, requirements above)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFS2bpHSZEU6"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Part 5: Run it and generate some text!\n",
    "\n",
    "---\n",
    "\n",
    "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs gave.\n",
    "\n",
    "**TODO:** \n",
    "\n",
    "**DONE:**\n",
    "* Create some cool output\n",
    "\n",
    "\n",
    "```\n",
    "[0m 9s (100 5%) 2.2169]\n",
    " Whaiss Mainde \n",
    "\n",
    "'\n",
    "\n",
    "he and the \n",
    "\n",
    "\n",
    "\n",
    "'od and roulll and Are say the \n",
    "rere. \n",
    "'Wor \n",
    "'Iow anond wes ou \n",
    "\n",
    "'Yi \n",
    "\n",
    "[0m 19s (200 10%) 2.0371]\n",
    "Whimbe. \n",
    "\n",
    "'Thhe \n",
    "on not of they was thou hit of \n",
    "sil ubat thith hy the seare \n",
    "as sower and of len beda \n",
    "\n",
    "[0m 29s (300 15%) 2.0051]\n",
    "Whis the cart. Whe courn!' 'Bu't of they aid dou giter of fintard of the not you ous, \n",
    "'Thas orntie it \n",
    "\n",
    "[0m 38s (400 20%) 1.8617]\n",
    "Wh win took be to the know the gost bing to kno wide dought, and he as of they thin. \n",
    "\n",
    "The Gonhis gura \n",
    "\n",
    "[0m 48s (500 25%) 1.9821]\n",
    "When of they singly call the and thave thing \n",
    "they the nowly we'tly by ands, of less be grarmines of t \n",
    "\n",
    "[0m 58s (600 30%) 1.8170]\n",
    "Whinds to mass of I \n",
    "not ken we ting and dour \n",
    "and they. \n",
    "\n",
    "\n",
    "'Wat res swe Ring set shat scmaid. The \n",
    "ha \n",
    "\n",
    "[1m 7s (700 35%) 2.0367]\n",
    "Whad ded troud wanty agy. Ve tanle gour the gone veart on hear, as dent far of the Ridgees.' \n",
    "\n",
    "'The Ri \n",
    "\n",
    "[1m 17s (800 40%) 1.9458]\n",
    "Whis is brouch Heared this lack and was weself, for on't \n",
    "abothom my and go staid it \n",
    "they curse arsh  \n",
    "\n",
    "[1m 27s (900 45%) 1.7522]\n",
    "Whout bear the \n",
    "Evening \n",
    "the pace spood, Arright the spaines beren the and Wish was was on the more yo \n",
    "\n",
    "[1m 37s (1000 50%) 1.6444]\n",
    "Whe Swarn. at colk. N(r)rce or they he \n",
    "wearing. And the on the he was are he said Pipin. \n",
    "\n",
    "'Yes and i \n",
    "\n",
    "[1m 47s (1100 55%) 1.8770]\n",
    "Whing at they and thins the Wil might \n",
    "happened you dlack rusting and thousting fy them, there lifted  \n",
    "\n",
    "[1m 57s (1200 60%) 1.9401]\n",
    "Wh the said Frodo eary him that the herremans! \n",
    "\n",
    "'I the Lager into came and broveener he sanly \n",
    "for \n",
    "s \n",
    "\n",
    "[2m 7s (1300 65%) 1.8095]\n",
    "When lest \n",
    "- in sound fair, and \n",
    "the Did dark he in the gose cilling the stand I in the sight. Frodo y \n",
    "\n",
    "[2m 16s (1400 70%) 1.9229]\n",
    "Whing in a shade and Mowarse round and parse could pass not a have partainly. ' for as I come of I \n",
    "le \n",
    "\n",
    "[2m 26s (1500 75%) 1.8169]\n",
    "Whese one her of in a lief that, \n",
    "but. 'We repagessed, \n",
    "wandere in these fair of long one have here my \n",
    "\n",
    "[2m 36s (1600 80%) 1.6635]\n",
    "Where fread in thougraned in woohis, on the the green the \n",
    "pohered alked tore becaming was seen what c \n",
    "\n",
    "[2m 46s (1700 85%) 1.7868]\n",
    "Whil neat \n",
    "came to \n",
    "is laked, \n",
    "and fourst on him grey now they as pass away aren have in the border sw \n",
    "\n",
    "[2m 56s (1800 90%) 1.6343]\n",
    "Wh magered. \n",
    "\n",
    "Then tell some tame had bear that \n",
    "came as it nome in \n",
    "to houbbirnen and to heardy. \n",
    "\n",
    "\n",
    "' \n",
    "\n",
    "[3m 6s (1900 95%) 1.8191]\n",
    "Who expey to must away be to the master felkly and for, what shours was alons? I had be the long to fo \n",
    "\n",
    "[3m 16s (2000 100%) 1.8725]\n",
    "White, and his of his in before that for brown before can then took on the fainter smass about rifall\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-nXFeCmdKodw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "n_epochs = 5000\n",
    "print_every = 200\n",
    "plot_every = 10\n",
    "hidden_size = 200\n",
    "n_layers = 3\n",
    "lr = 0.001\n",
    " \n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xKfozqw-6eqb",
    "outputId": "67ef24af-3479-442a-ef08-361386c99d4c"
   },
   "outputs": [],
   "source": [
    "# n_epochs = 2000\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  loss_ = train(*random_training_set())       \n",
    "  loss_avg += loss_\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
    "      print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "  if epoch % plot_every == 0:\n",
    "      all_losses.append(loss_avg / plot_every)\n",
    "      loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ee0so6aKJ5L8",
    "outputId": "ffd8ff7d-3b1c-42ba-9957-c78363b3154d"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
    "  start = random.randint(0,len(start_strings)-1)\n",
    "  print(start_strings[start])\n",
    "#   all_characters.index(string[c])\n",
    "  print(evaluate(start_strings[start], 200), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJhgDc2IauPE"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 6: Generate output on a different dataset\n",
    "\n",
    "---\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
    "\n",
    "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
    "\n",
    "**DONE:**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DL_Lab6.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
