{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALMerrill/cs474_labs_f2019/blob/master/DL_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Kp-azNgihL",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ALMerrill/cs474_labs_f2019/blob/master/DL_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Lab 4: Cancer Detection\n",
        "\n",
        "## Objective\n",
        "* To build a dense prediction model\n",
        "* To begin reading current papers in DNN research\n",
        "\n",
        "## Deliverable\n",
        "For this lab, you will turn in a notebook that describes your efforts at creating\n",
        "a pytorch radiologist. Your final deliverable is a notebook that has (1) deep network,\n",
        "(2) cost function, (3) method of calculating accuracy,\n",
        "(4) an image that shows the dense prediction produced by your network on the pos_test_000072.png image.\n",
        "This is an image in the test set that your network will not have seen before.\n",
        "This image, and the ground truth labeling, is shown below.\n",
        "(And is contained in the downloadable dataset below).\n",
        "\n",
        "![](http://liftothers.org/dokuwiki/lib/exe/fetch.php?w=200&tok=a8ac31&media=cs501r_f2016:pos_test_000072_output.png)\n",
        "<img src=\"http://liftothers.org/dokuwiki/lib/exe/fetch.php?media=cs501r_f2016:pos_test_000072.png\" width=\"200\">\n",
        "\n",
        "\n",
        "## Grading standards\n",
        "Your notebook will be graded on the following:\n",
        "* 40% Proper design, creation and debugging of a dense prediction network\n",
        "* 40% Proper implementation of a loss function and train/test set accuracy measure\n",
        "* 10% Tidy visualizations of loss of your dense predictor during training\n",
        "* 10% Test image output\n",
        "\n",
        "\n",
        "## Data set\n",
        "The data is given as a set of 1024×1024 PNG images. Each input image (in \n",
        "the ```inputs``` directory) is an RGB image of a section of tissue,\n",
        "and there a file with the same name (in the ```outputs``` directory) \n",
        "that has a dense labeling of whether or not a section of tissue is cancerous\n",
        "(white pixels mean “cancerous”, while black pixels mean “not cancerous”).\n",
        "\n",
        "The data has been pre-split for you into test and training splits.\n",
        "Filenames also reflect whether or not the image has any cancer at all \n",
        "(files starting with ```pos_``` have some cancerous pixels, while files \n",
        "starting with ```neg_``` have no cancer anywhere).\n",
        "All of the data is hand-labeled, so the dataset is not very large.\n",
        "That means that overfitting is a real possibility.\n",
        "\n",
        "## Description\n",
        "For a video including some tips and tricks that can help with this lab: [https://youtu.be/Ms19kgK_D8w](https://youtu.be/Ms19kgK_D8w)\n",
        "For this lab, you will implement a virtual radiologist.\n",
        "You are given images of possibly cancerous tissue samples, \n",
        "and you must build a detector that identifies where in the tissue cancer may reside.\n",
        "\n",
        "---\n",
        "\n",
        "### Part 0\n",
        "Watch and follow video tutorial:\n",
        "\n",
        "https://youtu.be/Ms19kgK_D8w\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Watch tutorial\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "### Part 1\n",
        "Implement a dense predictor\n",
        "\n",
        "In previous labs and lectures, we have talked about DNNs that classify an \n",
        "entire image as a single class. Here, however, we are interested in a more nuanced classification: \n",
        "given an input image, we would like to identify each pixel that is possibly cancerous. \n",
        "That means that instead of a single output, your network should output an “image”, \n",
        "where each output pixel of your network represents the probability that a pixel is cancerous.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Create a Network that classifies each pixel as a 1 or 0 for cancerous / not cancerous\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "___\n",
        "\n",
        "### Part 1a\n",
        "Implement your network topology\n",
        "\n",
        "\n",
        "Use the “Deep Convolution U-Net” from this paper: [(U-Net: Convolutional Networks for Biomedical Image Segmentation)](https://arxiv.org/pdf/1505.04597.pdf) \n",
        "\n",
        "![(Figure 1)](https://lh3.googleusercontent.com/qnHiB3B2KRxC3NjiSDtY08_DgDGTDsHcO6PP53oNRuct-p2QXCR-gyLkDveO850F2tTAhIOPC5Ha06NP9xq1JPsVAHlQ5UXA5V-9zkUrJHGhP_MNHFoRGnjBz1vn1p8P2rMWhlAb6HQ=w2400)\n",
        "\n",
        "You should use existing pytorch functions (not your own Conv2D module), such as ```nn.Conv2d```;\n",
        "you will also need the pytorch function ```torch.cat``` and ```nn.ConvTranspose2d```\n",
        "\n",
        "```torch.cat``` allows you to concatenate tensors.\n",
        "```nn.ConvTranspose2d``` is the opposite of ```nn.Conv2d```.\n",
        "It is used to bring an image from low res to higher res.\n",
        "[This blog](https://towardsdatascience.com/up-sampling-with-transposed-convolution-9ae4f2df52d0) should help you understand this function in detail.\n",
        "\n",
        "Note that the simplest network you could implement (with all the desired properties)\n",
        "is just a single convolution layer with two filters and no relu! \n",
        "Why is that? (of course it wouldn't work very well!)\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Understand the U-Net architecture\n",
        "* Understand concatenation of inputs from multiple prior layers\n",
        "* Understand ConvTranspose\n",
        "* Answer Question / Reflect on simplest network with the desired properties\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n",
        "___\n",
        "The intention of this lab is to learn how to make deep neural nets and implement loss function.\n",
        "Therefore we'll help you with the implementation of Dataset.\n",
        "This code will download the dataset for you so that you are ready to use it and focus on network\n",
        "implementation, losses and accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wQOefmcZVgTl",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# !pip3 install torch\n",
        "# !pip3 install torchvision\n",
        "# !pip3 install tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Il_53HLSWPTY",
        "colab": {}
      },
      "source": [
        "#log max trick (also picture on phone)\n",
        "#     maxes, _ = torch.max(y_hat, 1, keepdim=True)\n",
        "#     y_hat = y_hat - maxes\n",
        "#     y_hat = torch.exp(y_hat)\n",
        "#     y_hat = y_hat / torch.sum(y_hat, 1, keepdim=True)\n",
        "\n",
        "\n",
        "class CancerDataset(Dataset):\n",
        "  def __init__(self, root, download=True, size=512, train=True):\n",
        "    if download and not os.path.exists(os.path.join(root, 'cancer_data')):\n",
        "#       datasets.utils.download_url('http://liftothers.org/cancer_data.tar.gz', root, 'cancer_data.tar.gz', None)\n",
        "      datasets.utils.download_url('https://nolans-cs-bucket.s3-us-west-1.amazonaws.com/cancer_data.tar.gz', root, 'cancer_data.tar.gz', None)\n",
        "      self.extract_gzip(os.path.join(root, 'cancer_data.tar.gz'))\n",
        "      self.extract_tar(os.path.join(root, 'cancer_data.tar'))\n",
        "    \n",
        "    postfix = 'train' if train else 'test'\n",
        "    root = os.path.join(root, 'cancer_data', 'cancer_data')\n",
        "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, 'inputs_' + postfix) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))\n",
        "    self.label_folder = torchvision.datasets.ImageFolder(os.path.join(root, 'outputs_' + postfix) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_gzip(gzip_path, remove_finished=False):\n",
        "    print('Extracting {}'.format(gzip_path))\n",
        "    with open(gzip_path.replace('.gz', ''), 'wb') as out_f, gzip.GzipFile(gzip_path) as zip_f:\n",
        "      out_f.write(zip_f.read())\n",
        "    if remove_finished:\n",
        "      os.unlink(gzip_path)\n",
        "  \n",
        "  @staticmethod\n",
        "  def extract_tar(tar_path):\n",
        "    print('Untarring {}'.format(tar_path))\n",
        "    z = tarfile.TarFile(tar_path)\n",
        "    z.extractall(tar_path.replace('.tar', ''))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    img = self.dataset_folder[index]\n",
        "    label = self.label_folder[index]\n",
        "    return img[0],label[0][0]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return 100\n",
        "#     return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QY4owfQwm-Ni"
      },
      "source": [
        "___\n",
        "\n",
        "### Part 1b\n",
        "Implement a cost function\n",
        "\n",
        "You should still use cross-entropy as your cost function, but you may need to think hard about how exactly to set this up – your network should output cancer/not-cancer probabilities for each pixel, which can be viewed as a two-class classification problem.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Adapt CrossEntropyLoss for 2 class pixel classification\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XPgrP88aOtfy",
        "colab": {}
      },
      "source": [
        "# You'll probably want a function or something to test input / output sizes of the ConvTranspose2d layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jq22IyKanxo_",
        "colab": {}
      },
      "source": [
        "# Since you will be using the output of one network in two places(convolution and maxpooling),\n",
        "# you can't use nn.Sequential.\n",
        "# Instead you will write up the network like normal variable assignment as the example shown below:\n",
        "# You are welcome (and encouraged) to use the built-in batch normalization and dropout layer.\n",
        "\n",
        "# TODO: You need to change this to fit the UNet structure!!!\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "#     self.poolConv = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 2, padding = 1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out1 = F.relu(self.conv1(x))\n",
        "    out2 = F.relu(self.conv2(out1))\n",
        "    return out2\n",
        "#     return F.relu(self.poolConv(out2))  #probably don't want relu on final layer\n",
        "  \n",
        "  \n",
        "class ConvTransposeBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(ConvTransposeBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.convT1 = nn.ConvTranspose2d(out_channels, out_channels // 2, kernel_size = 4, stride = 2, padding = 1) #Is it fine to just divide the channels by 2? That way it comes out to the same when the other gets concatted on\n",
        "    \n",
        "  def forward(self, x, skip_connection=torch.Tensor([]).cuda(), last_layer=False):\n",
        "    x = torch.cat((skip_connection, x), 1)\n",
        "    out1 = F.relu(self.conv1(x))\n",
        "    out2 = F.relu(self.conv2(out1))\n",
        "    if last_layer:\n",
        "      return out2\n",
        "    out3 = F.relu(self.convT1(out2))\n",
        "    return out3\n",
        "      \n",
        "\n",
        "  \n",
        "class CancerDetection(nn.Module): #lab video at 39:00 for a bit of a description of the layout for these\n",
        "  def __init__(self):\n",
        "    super(CancerDetection, self).__init__()\n",
        "    self.block1 = ConvBlock(3, 64)\n",
        "    self.pool1 = nn.Conv2d(64, 64, kernel_size = 3, stride = 2, padding = 1)\n",
        "    self.block2 = ConvBlock(64, 128)\n",
        "    self.pool2 = nn.Conv2d(128, 128, kernel_size = 3, stride = 2, padding = 1)\n",
        "    self.block3 = ConvBlock(128, 256)\n",
        "    self.pool3 = nn.Conv2d(256, 256, kernel_size = 3, stride = 2, padding = 1)\n",
        "    self.block4 = ConvBlock(256, 512)\n",
        "    self.pool4 = nn.Conv2d(512, 512, kernel_size = 3, stride = 2, padding = 1)\n",
        "    #UpConv\n",
        "    self.block5 = ConvTransposeBlock(512, 1024)\n",
        "    self.block6 = ConvTransposeBlock(1024, 512)\n",
        "    self.block7 = ConvTransposeBlock(512, 256)\n",
        "    self.block8 = ConvTransposeBlock(256, 128)\n",
        "    self.block9 = ConvTransposeBlock(128, 64)\n",
        "    self.conv1x1 = nn.Conv2d(64, 2, kernel_size=1, stride=1)\n",
        "\n",
        "    \n",
        " \n",
        "  def forward(self, x):\n",
        "    print('\\nshapes')\n",
        "    print('x:',x.size())\n",
        "    out1 = self.block1(x)\n",
        "    pool1 = F.relu(self.pool1(out1))\n",
        "    out2 = self.block2(pool1)\n",
        "    pool2 = F.relu(self.pool2(out2))\n",
        "    out3 = self.block3(pool2)\n",
        "    pool3 = F.relu(self.pool3(out3))\n",
        "    out4 = self.block4(pool3)\n",
        "    pool4 = F.relu(self.pool4(out4))\n",
        "    #UpConv\n",
        "    out5 = self.block5(pool4)\n",
        "    out6 = self.block6(out5, skip_connection=out4)\n",
        "    out7 = self.block7(out6, skip_connection=out3)\n",
        "    out8 = self.block8(out7, skip_connection=out2)\n",
        "    out9 = self.block9(out8, skip_connection=out1, last_layer=True)\n",
        "    out10 = self.conv1x1(out9) #Make sure it is back to image size before this\n",
        "    print('final:', out10.size())\n",
        "    return out10\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NAjagHCdGNAh",
        "colab": {}
      },
      "source": [
        "# Create your datasets and neural network as you have before\n",
        "\n",
        "train_dataset = CancerDataset('root')\n",
        "val_dataset = CancerDataset('root', train=False)\n",
        "model = CancerDetection()\n",
        "model.cuda()\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=batch_size,\n",
        "                         num_workers =4, #check iterations/sec in tqdm to see how this helps or hurts\n",
        "                         pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                       batch_size=batch_size,\n",
        "                       num_workers =4,\n",
        "                       pin_memory=True)\n",
        "\n",
        "data_loaders = {'train': train_loader, 'val': val_loader}\n",
        "\n",
        "losses = []\n",
        "validations = []\n",
        "train_acc = []\n",
        "val_acc = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RkieTbwlYWPS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "496911d1-f591-47b1-ae7a-d793da615df9"
      },
      "source": [
        "# This is what was talked about in the video for memory management\n",
        "\n",
        "def accuracy(y_hat, y_truth):\n",
        "  # y_hat: batch x 2 x 512 x 512   Each channel holds the probabilities for that class\n",
        "  # y_truth: batch x 1 x 512 x 512\n",
        "  y_hat = y_hat[0]\n",
        "  y_truth = y_truth[0]\n",
        "  y_hat[0] = y_hat[0] > .5\n",
        "  y_hat[1] = y_hat[1] >= .5\n",
        "  intersection = torch.sum(y_hat[0] * y_truth)\n",
        "  #union = torch.sum(y_hat[0] + y_truth >= 1)  #from help session?\n",
        "  union = torch.sum(y_hat[0] + y_truth) - intersection\n",
        "  return intersection / union\n",
        "  \n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "def train():\n",
        "  for epoch in range(EPOCHS):\n",
        "    loop = tqdm(total=len(train_loader), position=0, leave=False)\n",
        "  \n",
        "    for batch, (x, y_truth) in enumerate(train_loader):\n",
        "      x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "      optimizer.zero_grad()\n",
        "      y_hat = model(x) \n",
        "      loss = objective(y_hat, y_truth.long())\n",
        "      loss.backward()\n",
        "\n",
        "      losses.append(loss.item())\n",
        "      acc = accuracy(y_hat, y_truth)\n",
        "      train_acc.append(acc)\n",
        "      mem = torch.cuda.memory_allocated(0) / 1e9\n",
        "\n",
        "      loop.set_description('epoch: {}, loss: {:.4f}, accuracy: {:.3f}, mem: {:.2f}'\n",
        "                           .format(epoch, loss, acc, mem))\n",
        "      loop.update(1)\n",
        "      optimizer.step()\n",
        "      if batch % 20 == 0:\n",
        "        y_hat_val = np.mean([accuracy(model(x.cuda()), y_truth.cuda()) for x, y_truth in val_loader])\n",
        "        val_acc.append((len(losses), y_hat_val))\n",
        "        val = np.mean([objective(model(x.cuda()), y.cuda()).item() \n",
        "                       for x, y in val_loader])\n",
        "        validations.append((len(losses), val))\n",
        "    loop.close()\n",
        "\n",
        "def scope():\n",
        "  try:\n",
        "    #your code for calling dataset and dataloader\n",
        "    gc.collect()\n",
        "    print(torch.cuda.memory_allocated(0) / 1e9)\n",
        "    \n",
        "    train()\n",
        "    # Call your model, figure out loss and accuracy\n",
        "    \n",
        "  except:\n",
        "    __ITB__()\n",
        "    \n",
        "scope()\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.1715328\n",
            "\n",
            "shapes\n",
            "x: torch.Size([2, 3, 512, 512])\n",
            "final: torch.Size([2, 2, 512, 512])\n",
            "torch.Size([2, 2, 512, 512]) torch.Size([2, 512, 512])\n",
            "torch.cuda.FloatTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.7159, accuracy: nan, mem: 0.36:   2%|▏         | 1/50 [00:02<02:09,  2.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "shapes\n",
            "x: torch.Size([2, 3, 512, 512])\n",
            "final: torch.Size([2, 2, 512, 512])\n",
            "\n",
            "shapes\n",
            "x: torch.Size([2, 3, 512, 512])\n",
            "final: torch.Size([2, 2, 512, 512])\n",
            "\n",
            "shapes\n",
            "x: torch.Size([2, 3, 512, 512])\n",
            "final: torch.Size([2, 2, 512, 512])\n",
            "\n",
            "shapes\n",
            "x: torch.Size([2, 3, 512, 512])\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-113-8676e30fea95>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m     38\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     39\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 40\u001b[0;31m         \u001b[0my_hat_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_truth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36my_hat_val\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mnp.mean\u001b[0m \u001b[0;34m= <function mean at 0x7f630b9ffbf8>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36maccuracy\u001b[0m \u001b[0;34m= <function accuracy at 0x7f62a60b6378>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mmodel\u001b[0m \u001b[0;34m= CancerDetection(\n",
            "  (block1): ConvBlock(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block2): ConvBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block3): ConvBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block4): ConvBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block5): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block6): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block7): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block8): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block9): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (conv1x1): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mx.cuda\u001b[0m \u001b[0;34m= <built-in method cuda of Tensor object at 0x7f62a608b990>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36my_truth.cuda\u001b[0m \u001b[0;34m= <built-in method cuda of Tensor object at 0x7f62a608bab0>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mx\u001b[0m \u001b[0;34m= tensor([[[[0.9490, 0.9569, 0.9490,  ..., 0.4941, 0.8275, 0.9412],\n",
            "          [0.9490, 0.9529, 0.9451,  ..., 0.4510, 0.7333, 0.8980],\n",
            "          [0.9451, 0.9490, 0.9451,  ..., 0.4902, 0.6314, 0.8588],\n",
            "          ...,\n",
            "          [0.7843, 0.8980, 0.8863,  ..., 0.4980, 0.4745, 0.3804],\n",
            "          [0.8667, 0.8980, 0.8157,  ..., 0.7451, 0.5373, 0.3686],\n",
            "          [0.9686, 0.9255, 0.8392,  ..., 0.9098, 0.6824, 0.4118]],\n",
            "\n",
            "         [[0.9412, 0.9490, 0.9529,  ..., 0.4118, 0.6235, 0.7490],\n",
            "          [0.9529, 0.9490, 0.9451,  ..., 0.3804, 0.5765, 0.6000],\n",
            "          [0.9529, 0.9490, 0.9451,  ..., 0.4039, 0.4824, 0.5412],\n",
            "          ...,\n",
            "          [0.7961, 0.8863, 0.8863,  ..., 0.4980, 0.4667, 0.4235],\n",
            "          [0.8627, 0.8902, 0.8196,  ..., 0.7059, 0.5255, 0.3843],\n",
            "          [0.9490, 0.9176, 0.8353,  ..., 0.8745, 0.6510, 0.4196]],\n",
            "\n",
            "         [[0.9412, 0.9412, 0.9490,  ..., 0.5216, 0.6627, 0.7686],\n",
            "          [0.9373, 0.9529, 0.9451,  ..., 0.5059, 0.6157, 0.6588],\n",
            "          [0.9412, 0.9529, 0.9373,  ..., 0.5412, 0.5490, 0.5804],\n",
            "          ...,\n",
            "          [0.7647, 0.8510, 0.8627,  ..., 0.6118, 0.5922, 0.5490],\n",
            "          [0.8471, 0.8667, 0.7804,  ..., 0.7647, 0.6314, 0.5216],\n",
            "          [0.9412, 0.9020, 0.8196,  ..., 0.8745, 0.7333, 0.5255]]],\n",
            "\n",
            "\n",
            "        [[[0.3255, 0.3255, 0.2471,  ..., 0.8980, 0.8941, 0.8941],\n",
            "          [0.8588, 0.8588, 0.7569,  ..., 0.9098, 0.8980, 0.9216],\n",
            "          [0.9412, 0.9216, 0.9490,  ..., 0.9098, 0.9098, 0.9216],\n",
            "          ...,\n",
            "          [0.3098, 0.2902, 0.4706,  ..., 0.9137, 0.9020, 0.9137],\n",
            "          [0.3569, 0.3804, 0.6471,  ..., 0.9059, 0.9098, 0.8941],\n",
            "          [0.5098, 0.5961, 0.7176,  ..., 0.9020, 0.9098, 0.8980]],\n",
            "\n",
            "         [[0.2235, 0.2353, 0.1647,  ..., 0.8980, 0.8863, 0.8824],\n",
            "          [0.7608, 0.7608, 0.6549,  ..., 0.9020, 0.8941, 0.8980],\n",
            "          [0.9216, 0.8863, 0.9216,  ..., 0.8941, 0.8980, 0.8941],\n",
            "          ...,\n",
            "          [0.3451, 0.3451, 0.5294,  ..., 0.8980, 0.8902, 0.8824],\n",
            "          [0.3804, 0.4353, 0.6784,  ..., 0.8863, 0.9020, 0.8863],\n",
            "          [0.5333, 0.5843, 0.7098,  ..., 0.8863, 0.9020, 0.8941]],\n",
            "\n",
            "         [[0.1843, 0.1882, 0.1255,  ..., 0.8745, 0.8667, 0.8784],\n",
            "          [0.6275, 0.6510, 0.5647,  ..., 0.8980, 0.8745, 0.8980],\n",
            "          [0.8745, 0.8471, 0.8745,  ..., 0.8863, 0.8902, 0.8902],\n",
            "          ...,\n",
            "          [0.5059, 0.5098, 0.6314,  ..., 0.8784, 0.8784, 0.8824],\n",
            "          [0.5216, 0.5412, 0.7059,  ..., 0.8745, 0.8745, 0.8706],\n",
            "          [0.6196, 0.6157, 0.6784,  ..., 0.8667, 0.8627, 0.8745]]]],\n",
            "       device='cuda:0')\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36my_truth\u001b[0m \u001b[0;34m= tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mval_loader\u001b[0m \u001b[0;34m= <torch.utils.data.dataloader.DataLoader object at 0x7f62a5fd7fd0>\u001b[0m\n",
            "\u001b[1;32m     41\u001b[0m         \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     42\u001b[0m         val = np.mean([objective(model(x.cuda()), y.cuda()).item() \n",
            "\n",
            "\u001b[0;32m<ipython-input-113-8676e30fea95>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0=<torch.utils.data.dataloader._DataLoaderIter object>)\u001b[0m\n",
            "\u001b[1;32m     38\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     39\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 40\u001b[0;31m         \u001b[0my_hat_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_truth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mglobal\u001b[0m \u001b[0;36my_hat_val\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mnp.mean\u001b[0m \u001b[0;34m= <function mean at 0x7f630b9ffbf8>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36maccuracy\u001b[0m \u001b[0;34m= <function accuracy at 0x7f62a60b6378>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mmodel\u001b[0m \u001b[0;34m= CancerDetection(\n",
            "  (block1): ConvBlock(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block2): ConvBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block3): ConvBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block4): ConvBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block5): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block6): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block7): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block8): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block9): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (conv1x1): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mx.cuda\u001b[0m \u001b[0;34m= <built-in method cuda of Tensor object at 0x7f62a5fb7558>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36my_truth.cuda\u001b[0m \u001b[0;34m= <built-in method cuda of Tensor object at 0x7f62a5fb7cf0>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mx\u001b[0m \u001b[0;34m= tensor([[[[0.8863, 0.8902, 0.9020,  ..., 0.6314, 0.6706, 0.6314],\n",
            "          [0.8824, 0.9020, 0.8941,  ..., 0.6941, 0.6196, 0.6000],\n",
            "          [0.8902, 0.8863, 0.8784,  ..., 0.6078, 0.6784, 0.6392],\n",
            "          ...,\n",
            "          [0.8902, 0.8902, 0.8667,  ..., 0.6039, 0.6392, 0.5765],\n",
            "          [0.8824, 0.8863, 0.8667,  ..., 0.6157, 0.5961, 0.5529],\n",
            "          [0.8863, 0.8784, 0.8784,  ..., 0.6510, 0.5294, 0.4275]],\n",
            "\n",
            "         [[0.8784, 0.8824, 0.8902,  ..., 0.5843, 0.6157, 0.5922],\n",
            "          [0.8824, 0.8980, 0.8824,  ..., 0.6510, 0.5922, 0.5686],\n",
            "          [0.8824, 0.8784, 0.8784,  ..., 0.5686, 0.6275, 0.5922],\n",
            "          ...,\n",
            "          [0.8784, 0.8745, 0.8667,  ..., 0.5569, 0.5882, 0.5412],\n",
            "          [0.8863, 0.8706, 0.8667,  ..., 0.5922, 0.5529, 0.5176],\n",
            "          [0.8824, 0.8627, 0.8588,  ..., 0.6039, 0.4667, 0.3843]],\n",
            "\n",
            "         [[0.8706, 0.8784, 0.8980,  ..., 0.5412, 0.5647, 0.5333],\n",
            "          [0.8824, 0.8902, 0.8863,  ..., 0.6000, 0.5373, 0.5098],\n",
            "          [0.8902, 0.8902, 0.8863,  ..., 0.5216, 0.5765, 0.5333],\n",
            "          ...,\n",
            "          [0.8706, 0.8667, 0.8588,  ..., 0.5098, 0.5333, 0.4824],\n",
            "          [0.8745, 0.8627, 0.8667,  ..., 0.5412, 0.4980, 0.4706],\n",
            "          [0.8745, 0.8667, 0.8745,  ..., 0.5529, 0.4235, 0.3451]]],\n",
            "\n",
            "\n",
            "        [[[0.8275, 0.8824, 0.9725,  ..., 0.5843, 0.4431, 0.4392],\n",
            "          [0.9216, 0.9059, 0.9608,  ..., 0.7059, 0.5098, 0.4863],\n",
            "          [0.8784, 0.8549, 0.9608,  ..., 0.7765, 0.5137, 0.4471],\n",
            "          ...,\n",
            "          [0.8902, 0.8706, 0.8902,  ..., 0.9333, 0.9020, 0.8980],\n",
            "          [0.9451, 0.8824, 0.9137,  ..., 0.9059, 0.9059, 0.8902],\n",
            "          [0.9569, 0.9176, 0.8941,  ..., 0.9137, 0.9176, 0.8941]],\n",
            "\n",
            "         [[0.8157, 0.8902, 0.9804,  ..., 0.5882, 0.4706, 0.4667],\n",
            "          [0.8824, 0.9020, 0.9608,  ..., 0.6863, 0.5333, 0.5059],\n",
            "          [0.8510, 0.8353, 0.9569,  ..., 0.7647, 0.5373, 0.4745],\n",
            "          ...,\n",
            "          [0.8039, 0.7882, 0.8275,  ..., 0.8902, 0.8706, 0.8745],\n",
            "          [0.8471, 0.8000, 0.8588,  ..., 0.8667, 0.8706, 0.8667],\n",
            "          [0.8784, 0.8471, 0.8431,  ..., 0.8784, 0.8824, 0.8588]],\n",
            "\n",
            "         [[0.7569, 0.8510, 0.9804,  ..., 0.6824, 0.6078, 0.6157],\n",
            "          [0.8627, 0.8510, 0.9412,  ..., 0.7451, 0.6627, 0.6392],\n",
            "          [0.8118, 0.8039, 0.9373,  ..., 0.7922, 0.6784, 0.6275],\n",
            "          ...,\n",
            "          [0.7608, 0.7412, 0.7804,  ..., 0.8510, 0.8431, 0.8275],\n",
            "          [0.7961, 0.7569, 0.8118,  ..., 0.8431, 0.8275, 0.8353],\n",
            "          [0.8235, 0.8000, 0.7882,  ..., 0.8471, 0.8392, 0.8353]]]])\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36my_truth\u001b[0m \u001b[0;34m= tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]])\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mval_loader\u001b[0m \u001b[0;34m= <torch.utils.data.dataloader.DataLoader object at 0x7f62a5fd7fd0>\u001b[0m\n",
            "\u001b[1;32m     41\u001b[0m         \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     42\u001b[0m         val = np.mean([objective(model(x.cuda()), y.cuda()).item() \n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=CancerDetection(\n",
            "  (block1): ConvBlock(\n",
            "    (con...onv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "), *input=(tensor([[[[0.8863, 0.8902, 0.9020,  ..., 0.6314,...8471, 0.8392, 0.8353]]]],\n",
            "       device='cuda:0'),), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.forward\u001b[0m \u001b[0;34m= <bound method CancerDetection.forward of CancerDetection(\n",
            "  (block1): ConvBlock(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block2): ConvBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block3): ConvBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block4): ConvBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (pool4): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (block5): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block6): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block7): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block8): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (block9): ConvTransposeBlock(\n",
            "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (convT1): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "  )\n",
            "  (conv1x1): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            ")>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= (tensor([[[[0.8863, 0.8902, 0.9020,  ..., 0.6314, 0.6706, 0.6314],\n",
            "          [0.8824, 0.9020, 0.8941,  ..., 0.6941, 0.6196, 0.6000],\n",
            "          [0.8902, 0.8863, 0.8784,  ..., 0.6078, 0.6784, 0.6392],\n",
            "          ...,\n",
            "          [0.8902, 0.8902, 0.8667,  ..., 0.6039, 0.6392, 0.5765],\n",
            "          [0.8824, 0.8863, 0.8667,  ..., 0.6157, 0.5961, 0.5529],\n",
            "          [0.8863, 0.8784, 0.8784,  ..., 0.6510, 0.5294, 0.4275]],\n",
            "\n",
            "         [[0.8784, 0.8824, 0.8902,  ..., 0.5843, 0.6157, 0.5922],\n",
            "          [0.8824, 0.8980, 0.8824,  ..., 0.6510, 0.5922, 0.5686],\n",
            "          [0.8824, 0.8784, 0.8784,  ..., 0.5686, 0.6275, 0.5922],\n",
            "          ...,\n",
            "          [0.8784, 0.8745, 0.8667,  ..., 0.5569, 0.5882, 0.5412],\n",
            "          [0.8863, 0.8706, 0.8667,  ..., 0.5922, 0.5529, 0.5176],\n",
            "          [0.8824, 0.8627, 0.8588,  ..., 0.6039, 0.4667, 0.3843]],\n",
            "\n",
            "         [[0.8706, 0.8784, 0.8980,  ..., 0.5412, 0.5647, 0.5333],\n",
            "          [0.8824, 0.8902, 0.8863,  ..., 0.6000, 0.5373, 0.5098],\n",
            "          [0.8902, 0.8902, 0.8863,  ..., 0.5216, 0.5765, 0.5333],\n",
            "          ...,\n",
            "          [0.8706, 0.8667, 0.8588,  ..., 0.5098, 0.5333, 0.4824],\n",
            "          [0.8745, 0.8627, 0.8667,  ..., 0.5412, 0.4980, 0.4706],\n",
            "          [0.8745, 0.8667, 0.8745,  ..., 0.5529, 0.4235, 0.3451]]],\n",
            "\n",
            "\n",
            "        [[[0.8275, 0.8824, 0.9725,  ..., 0.5843, 0.4431, 0.4392],\n",
            "          [0.9216, 0.9059, 0.9608,  ..., 0.7059, 0.5098, 0.4863],\n",
            "          [0.8784, 0.8549, 0.9608,  ..., 0.7765, 0.5137, 0.4471],\n",
            "          ...,\n",
            "          [0.8902, 0.8706, 0.8902,  ..., 0.9333, 0.9020, 0.8980],\n",
            "          [0.9451, 0.8824, 0.9137,  ..., 0.9059, 0.9059, 0.8902],\n",
            "          [0.9569, 0.9176, 0.8941,  ..., 0.9137, 0.9176, 0.8941]],\n",
            "\n",
            "         [[0.8157, 0.8902, 0.9804,  ..., 0.5882, 0.4706, 0.4667],\n",
            "          [0.8824, 0.9020, 0.9608,  ..., 0.6863, 0.5333, 0.5059],\n",
            "          [0.8510, 0.8353, 0.9569,  ..., 0.7647, 0.5373, 0.4745],\n",
            "          ...,\n",
            "          [0.8039, 0.7882, 0.8275,  ..., 0.8902, 0.8706, 0.8745],\n",
            "          [0.8471, 0.8000, 0.8588,  ..., 0.8667, 0.8706, 0.8667],\n",
            "          [0.8784, 0.8471, 0.8431,  ..., 0.8784, 0.8824, 0.8588]],\n",
            "\n",
            "         [[0.7569, 0.8510, 0.9804,  ..., 0.6824, 0.6078, 0.6157],\n",
            "          [0.8627, 0.8510, 0.9412,  ..., 0.7451, 0.6627, 0.6392],\n",
            "          [0.8118, 0.8039, 0.9373,  ..., 0.7922, 0.6784, 0.6275],\n",
            "          ...,\n",
            "          [0.7608, 0.7412, 0.7804,  ..., 0.8510, 0.8431, 0.8275],\n",
            "          [0.7961, 0.7569, 0.8118,  ..., 0.8431, 0.8275, 0.8353],\n",
            "          [0.8235, 0.8000, 0.7882,  ..., 0.8471, 0.8392, 0.8353]]]],\n",
            "       device='cuda:0'),)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m<ipython-input-111-6b738f6f1def>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self=CancerDetection(\n",
            "  (block1): ConvBlock(\n",
            "    (con...onv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "), x=tensor([[[[0.8863, 0.8902, 0.9020,  ..., 0.6314,...8471, 0.8392, 0.8353]]]],\n",
            "       device='cuda:0'))\u001b[0m\n",
            "\u001b[1;32m     68\u001b[0m     \u001b[0mout6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     69\u001b[0m     \u001b[0mout7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mout8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mout8\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.block8\u001b[0m \u001b[0;34m= ConvTransposeBlock(\n",
            "  (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convT1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            ")\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mout7\u001b[0m \u001b[0;34m= tensor([[[[1.6691e-02, 1.8203e-02, 2.0714e-02,  ..., 1.7862e-02,\n",
            "           2.0431e-02, 1.6569e-02],\n",
            "          [2.3569e-02, 1.6026e-02, 2.7055e-02,  ..., 1.6609e-02,\n",
            "           2.6318e-02, 1.3310e-02],\n",
            "          [1.4045e-02, 1.7403e-02, 1.4486e-02,  ..., 1.6934e-02,\n",
            "           1.4153e-02, 1.6205e-02],\n",
            "          ...,\n",
            "          [2.3066e-02, 1.5061e-02, 2.6489e-02,  ..., 1.5202e-02,\n",
            "           2.5549e-02, 1.2951e-02],\n",
            "          [1.3559e-02, 1.8297e-02, 1.3441e-02,  ..., 1.7683e-02,\n",
            "           1.3604e-02, 1.6575e-02],\n",
            "          [1.9301e-02, 1.4630e-02, 1.9787e-02,  ..., 1.4484e-02,\n",
            "           1.9704e-02, 1.2765e-02]],\n",
            "\n",
            "         [[7.1585e-03, 6.0904e-03, 5.6193e-03,  ..., 6.1607e-03,\n",
            "           5.2778e-03, 8.2199e-03],\n",
            "          [1.0918e-02, 9.2902e-03, 6.9305e-03,  ..., 8.4182e-03,\n",
            "           5.9494e-03, 1.1217e-02],\n",
            "          [5.8092e-03, 7.3487e-03, 4.6101e-03,  ..., 8.0006e-03,\n",
            "           4.0557e-03, 9.6304e-03],\n",
            "          ...,\n",
            "          [1.0768e-02, 8.5527e-03, 7.0543e-03,  ..., 7.2382e-03,\n",
            "           6.2614e-03, 1.0745e-02],\n",
            "          [5.7861e-03, 5.9034e-03, 5.1282e-03,  ..., 6.6696e-03,\n",
            "           4.7353e-03, 9.1886e-03],\n",
            "          [1.0999e-02, 7.9991e-03, 1.0988e-02,  ..., 7.6063e-03,\n",
            "           1.0981e-02, 9.4832e-03]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 1.1108e-03,  ..., 0.0000e+00,\n",
            "           1.5085e-03, 0.0000e+00],\n",
            "          [0.0000e+00, 1.8641e-04, 2.8818e-03,  ..., 7.8187e-04,\n",
            "           3.0484e-03, 1.3277e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 2.8862e-04],\n",
            "          ...,\n",
            "          [0.0000e+00, 7.5911e-04, 2.9899e-03,  ..., 1.5294e-03,\n",
            "           3.4290e-03, 1.5628e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 7.4091e-05,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 7.9690e-04],\n",
            "          [5.5339e-05, 0.0000e+00, 2.9805e-03,  ..., 0.0000e+00,\n",
            "           3.0343e-03, 0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.4548e-02, 1.1789e-02, 1.8029e-02,  ..., 1.1393e-02,\n",
            "           1.8121e-02, 1.1035e-02],\n",
            "          [9.1879e-03, 9.4631e-03, 1.1675e-02,  ..., 8.4909e-03,\n",
            "           1.0130e-02, 1.0193e-02],\n",
            "          [1.6678e-02, 1.2088e-02, 2.0424e-02,  ..., 1.1832e-02,\n",
            "           1.9871e-02, 1.1356e-02],\n",
            "          ...,\n",
            "          [8.6355e-03, 9.7735e-03, 1.1478e-02,  ..., 9.8365e-03,\n",
            "           1.0684e-02, 1.1130e-02],\n",
            "          [1.6575e-02, 1.1793e-02, 2.0494e-02,  ..., 1.1666e-02,\n",
            "           1.9578e-02, 1.1557e-02],\n",
            "          [1.1282e-02, 1.0832e-02, 1.2471e-02,  ..., 1.1493e-02,\n",
            "           1.2891e-02, 1.1956e-02]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[1.6690e-02, 1.8200e-02, 2.0713e-02,  ..., 1.7864e-02,\n",
            "           2.0441e-02, 1.6568e-02],\n",
            "          [2.3569e-02, 1.6027e-02, 2.7052e-02,  ..., 1.6597e-02,\n",
            "           2.6305e-02, 1.3308e-02],\n",
            "          [1.4044e-02, 1.7406e-02, 1.4481e-02,  ..., 1.6932e-02,\n",
            "           1.4166e-02, 1.6195e-02],\n",
            "          ...,\n",
            "          [2.3066e-02, 1.5060e-02, 2.6491e-02,  ..., 1.5186e-02,\n",
            "           2.5537e-02, 1.2943e-02],\n",
            "          [1.3559e-02, 1.8298e-02, 1.3442e-02,  ..., 1.7661e-02,\n",
            "           1.3598e-02, 1.6571e-02],\n",
            "          [1.9302e-02, 1.4628e-02, 1.9788e-02,  ..., 1.4478e-02,\n",
            "           1.9694e-02, 1.2766e-02]],\n",
            "\n",
            "         [[7.1598e-03, 6.0880e-03, 5.6221e-03,  ..., 6.1584e-03,\n",
            "           5.2860e-03, 8.2200e-03],\n",
            "          [1.0915e-02, 9.2851e-03, 6.9307e-03,  ..., 8.4039e-03,\n",
            "           5.9498e-03, 1.1203e-02],\n",
            "          [5.8103e-03, 7.3530e-03, 4.6118e-03,  ..., 7.9996e-03,\n",
            "           4.0576e-03, 9.6287e-03],\n",
            "          ...,\n",
            "          [1.0770e-02, 8.5549e-03, 7.0559e-03,  ..., 7.2347e-03,\n",
            "           6.2436e-03, 1.0741e-02],\n",
            "          [5.7880e-03, 5.9019e-03, 5.1307e-03,  ..., 6.6757e-03,\n",
            "           4.7553e-03, 9.1919e-03],\n",
            "          [1.0999e-02, 8.0006e-03, 1.0989e-02,  ..., 7.6072e-03,\n",
            "           1.0973e-02, 9.4833e-03]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 1.1111e-03,  ..., 0.0000e+00,\n",
            "           1.5080e-03, 0.0000e+00],\n",
            "          [0.0000e+00, 1.8272e-04, 2.8776e-03,  ..., 7.6888e-04,\n",
            "           3.0376e-03, 1.3246e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 2.8805e-04],\n",
            "          ...,\n",
            "          [0.0000e+00, 7.5974e-04, 2.9872e-03,  ..., 1.5302e-03,\n",
            "           3.3993e-03, 1.5667e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 7.7945e-05,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 7.9567e-04],\n",
            "          [5.4519e-05, 0.0000e+00, 2.9779e-03,  ..., 0.0000e+00,\n",
            "           3.0243e-03, 0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.4548e-02, 1.1794e-02, 1.8026e-02,  ..., 1.1392e-02,\n",
            "           1.8105e-02, 1.1031e-02],\n",
            "          [9.1864e-03, 9.4629e-03, 1.1677e-02,  ..., 8.4867e-03,\n",
            "           1.0132e-02, 1.0185e-02],\n",
            "          [1.6676e-02, 1.2093e-02, 2.0421e-02,  ..., 1.1843e-02,\n",
            "           1.9838e-02, 1.1353e-02],\n",
            "          ...,\n",
            "          [8.6347e-03, 9.7761e-03, 1.1476e-02,  ..., 9.8545e-03,\n",
            "           1.0672e-02, 1.1142e-02],\n",
            "          [1.6574e-02, 1.1793e-02, 2.0491e-02,  ..., 1.1668e-02,\n",
            "           1.9582e-02, 1.1557e-02],\n",
            "          [1.1282e-02, 1.0831e-02, 1.2469e-02,  ..., 1.1493e-02,\n",
            "           1.2892e-02, 1.1958e-02]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mskip_connection\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mout2\u001b[0m \u001b[0;34m= tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[3.7424e-02, 5.7328e-02, 5.9981e-02,  ..., 4.8496e-02,\n",
            "           5.0257e-02, 4.5475e-02],\n",
            "          [4.1837e-02, 6.5709e-02, 6.4572e-02,  ..., 5.2826e-02,\n",
            "           5.7085e-02, 4.8095e-02],\n",
            "          [4.3037e-02, 7.3230e-02, 7.4771e-02,  ..., 6.0269e-02,\n",
            "           5.9538e-02, 4.9949e-02],\n",
            "          ...,\n",
            "          [4.5910e-02, 8.4429e-02, 8.6344e-02,  ..., 6.8269e-02,\n",
            "           6.5975e-02, 5.1534e-02],\n",
            "          [4.3252e-02, 7.2896e-02, 7.3493e-02,  ..., 5.8535e-02,\n",
            "           5.7096e-02, 4.5978e-02],\n",
            "          [3.8226e-02, 5.8252e-02, 5.8290e-02,  ..., 4.8835e-02,\n",
            "           4.8237e-02, 3.3215e-02]],\n",
            "\n",
            "         [[1.0170e-02, 1.8852e-02, 1.6926e-02,  ..., 1.4521e-02,\n",
            "           1.3836e-02, 9.5649e-03],\n",
            "          [4.5060e-03, 0.0000e+00, 0.0000e+00,  ..., 2.3803e-03,\n",
            "           2.3623e-03, 3.1167e-03],\n",
            "          [1.6007e-03, 0.0000e+00, 0.0000e+00,  ..., 3.9485e-03,\n",
            "           5.0061e-03, 3.1599e-03],\n",
            "          ...,\n",
            "          [5.9227e-04, 0.0000e+00, 0.0000e+00,  ..., 2.9096e-03,\n",
            "           4.6424e-03, 2.5288e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 1.1491e-03],\n",
            "          [6.3728e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           3.3082e-03, 2.7107e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 8.8935e-03],\n",
            "          [0.0000e+00, 5.5319e-03, 9.6253e-03,  ..., 1.2417e-02,\n",
            "           1.4318e-02, 2.2602e-02],\n",
            "          [0.0000e+00, 7.0833e-03, 5.2045e-03,  ..., 8.8066e-03,\n",
            "           1.0756e-02, 1.8887e-02],\n",
            "          ...,\n",
            "          [0.0000e+00, 2.3062e-03, 5.1363e-03,  ..., 8.9744e-03,\n",
            "           1.1718e-02, 1.9685e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3414e-03,\n",
            "           1.1928e-02, 1.6431e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.6265e-03, 4.7896e-03]]],\n",
            "\n",
            "\n",
            "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[3.8017e-02, 5.7864e-02, 5.8703e-02,  ..., 5.7063e-02,\n",
            "           5.5233e-02, 4.5789e-02],\n",
            "          [4.1696e-02, 6.6280e-02, 6.2281e-02,  ..., 6.6749e-02,\n",
            "           6.3735e-02, 5.3221e-02],\n",
            "          [4.1769e-02, 7.1650e-02, 7.2896e-02,  ..., 7.6764e-02,\n",
            "           7.3694e-02, 5.6291e-02],\n",
            "          ...,\n",
            "          [4.5492e-02, 8.5447e-02, 8.7504e-02,  ..., 8.9515e-02,\n",
            "           8.5924e-02, 6.2569e-02],\n",
            "          [4.3323e-02, 7.3850e-02, 7.3080e-02,  ..., 7.4809e-02,\n",
            "           7.1714e-02, 5.6310e-02],\n",
            "          [3.8283e-02, 5.8513e-02, 5.8520e-02,  ..., 5.7730e-02,\n",
            "           5.6139e-02, 3.6637e-02]],\n",
            "\n",
            "         [[1.1349e-02, 1.8237e-02, 1.7504e-02,  ..., 1.3996e-02,\n",
            "           1.3361e-02, 5.8436e-03],\n",
            "          [5.6381e-03, 0.0000e+00, 0.0000e+00,  ..., 3.0325e-05,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.4730e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.6389e-03, 0.0000e+00],\n",
            "          ...,\n",
            "          [5.5460e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.4691e-03, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.1331e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           3.5329e-03, 3.2142e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 9.6289e-03],\n",
            "          [0.0000e+00, 5.4434e-03, 1.1444e-02,  ..., 7.5028e-03,\n",
            "           1.3013e-02, 2.3276e-02],\n",
            "          [0.0000e+00, 8.1313e-03, 7.1195e-03,  ..., 5.8391e-03,\n",
            "           1.0034e-02, 1.8296e-02],\n",
            "          ...,\n",
            "          [0.0000e+00, 3.1040e-03, 4.8398e-03,  ..., 3.6523e-03,\n",
            "           1.0771e-02, 2.1992e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.1144e-02, 1.9183e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.2780e-03, 5.5231e-03]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)\u001b[0m\n",
            "\u001b[1;32m     71\u001b[0m     \u001b[0mout9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_connection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     72\u001b[0m     \u001b[0mout10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout9\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Make sure it is back to image size before this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=ConvTransposeBlock(\n",
            "  (conv1): Conv2d(256, 128, ...nel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "), *input=(tensor([[[[1.6691e-02, 1.8203e-02, 2.0714e-02,  ... device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>),), **kwargs={'skip_connection': tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ... device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)})\u001b[0m\n",
            "\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.forward\u001b[0m \u001b[0;34m= <bound method ConvTransposeBlock.forward of ConvTransposeBlock(\n",
            "  (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (convT1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            ")>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= (tensor([[[[1.6691e-02, 1.8203e-02, 2.0714e-02,  ..., 1.7862e-02,\n",
            "           2.0431e-02, 1.6569e-02],\n",
            "          [2.3569e-02, 1.6026e-02, 2.7055e-02,  ..., 1.6609e-02,\n",
            "           2.6318e-02, 1.3310e-02],\n",
            "          [1.4045e-02, 1.7403e-02, 1.4486e-02,  ..., 1.6934e-02,\n",
            "           1.4153e-02, 1.6205e-02],\n",
            "          ...,\n",
            "          [2.3066e-02, 1.5061e-02, 2.6489e-02,  ..., 1.5202e-02,\n",
            "           2.5549e-02, 1.2951e-02],\n",
            "          [1.3559e-02, 1.8297e-02, 1.3441e-02,  ..., 1.7683e-02,\n",
            "           1.3604e-02, 1.6575e-02],\n",
            "          [1.9301e-02, 1.4630e-02, 1.9787e-02,  ..., 1.4484e-02,\n",
            "           1.9704e-02, 1.2765e-02]],\n",
            "\n",
            "         [[7.1585e-03, 6.0904e-03, 5.6193e-03,  ..., 6.1607e-03,\n",
            "           5.2778e-03, 8.2199e-03],\n",
            "          [1.0918e-02, 9.2902e-03, 6.9305e-03,  ..., 8.4182e-03,\n",
            "           5.9494e-03, 1.1217e-02],\n",
            "          [5.8092e-03, 7.3487e-03, 4.6101e-03,  ..., 8.0006e-03,\n",
            "           4.0557e-03, 9.6304e-03],\n",
            "          ...,\n",
            "          [1.0768e-02, 8.5527e-03, 7.0543e-03,  ..., 7.2382e-03,\n",
            "           6.2614e-03, 1.0745e-02],\n",
            "          [5.7861e-03, 5.9034e-03, 5.1282e-03,  ..., 6.6696e-03,\n",
            "           4.7353e-03, 9.1886e-03],\n",
            "          [1.0999e-02, 7.9991e-03, 1.0988e-02,  ..., 7.6063e-03,\n",
            "           1.0981e-02, 9.4832e-03]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 1.1108e-03,  ..., 0.0000e+00,\n",
            "           1.5085e-03, 0.0000e+00],\n",
            "          [0.0000e+00, 1.8641e-04, 2.8818e-03,  ..., 7.8187e-04,\n",
            "           3.0484e-03, 1.3277e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 2.8862e-04],\n",
            "          ...,\n",
            "          [0.0000e+00, 7.5911e-04, 2.9899e-03,  ..., 1.5294e-03,\n",
            "           3.4290e-03, 1.5628e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 7.4091e-05,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 7.9690e-04],\n",
            "          [5.5339e-05, 0.0000e+00, 2.9805e-03,  ..., 0.0000e+00,\n",
            "           3.0343e-03, 0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.4548e-02, 1.1789e-02, 1.8029e-02,  ..., 1.1393e-02,\n",
            "           1.8121e-02, 1.1035e-02],\n",
            "          [9.1879e-03, 9.4631e-03, 1.1675e-02,  ..., 8.4909e-03,\n",
            "           1.0130e-02, 1.0193e-02],\n",
            "          [1.6678e-02, 1.2088e-02, 2.0424e-02,  ..., 1.1832e-02,\n",
            "           1.9871e-02, 1.1356e-02],\n",
            "          ...,\n",
            "          [8.6355e-03, 9.7735e-03, 1.1478e-02,  ..., 9.8365e-03,\n",
            "           1.0684e-02, 1.1130e-02],\n",
            "          [1.6575e-02, 1.1793e-02, 2.0494e-02,  ..., 1.1666e-02,\n",
            "           1.9578e-02, 1.1557e-02],\n",
            "          [1.1282e-02, 1.0832e-02, 1.2471e-02,  ..., 1.1493e-02,\n",
            "           1.2891e-02, 1.1956e-02]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]],\n",
            "\n",
            "\n",
            "        [[[1.6690e-02, 1.8200e-02, 2.0713e-02,  ..., 1.7864e-02,\n",
            "           2.0441e-02, 1.6568e-02],\n",
            "          [2.3569e-02, 1.6027e-02, 2.7052e-02,  ..., 1.6597e-02,\n",
            "           2.6305e-02, 1.3308e-02],\n",
            "          [1.4044e-02, 1.7406e-02, 1.4481e-02,  ..., 1.6932e-02,\n",
            "           1.4166e-02, 1.6195e-02],\n",
            "          ...,\n",
            "          [2.3066e-02, 1.5060e-02, 2.6491e-02,  ..., 1.5186e-02,\n",
            "           2.5537e-02, 1.2943e-02],\n",
            "          [1.3559e-02, 1.8298e-02, 1.3442e-02,  ..., 1.7661e-02,\n",
            "           1.3598e-02, 1.6571e-02],\n",
            "          [1.9302e-02, 1.4628e-02, 1.9788e-02,  ..., 1.4478e-02,\n",
            "           1.9694e-02, 1.2766e-02]],\n",
            "\n",
            "         [[7.1598e-03, 6.0880e-03, 5.6221e-03,  ..., 6.1584e-03,\n",
            "           5.2860e-03, 8.2200e-03],\n",
            "          [1.0915e-02, 9.2851e-03, 6.9307e-03,  ..., 8.4039e-03,\n",
            "           5.9498e-03, 1.1203e-02],\n",
            "          [5.8103e-03, 7.3530e-03, 4.6118e-03,  ..., 7.9996e-03,\n",
            "           4.0576e-03, 9.6287e-03],\n",
            "          ...,\n",
            "          [1.0770e-02, 8.5549e-03, 7.0559e-03,  ..., 7.2347e-03,\n",
            "           6.2436e-03, 1.0741e-02],\n",
            "          [5.7880e-03, 5.9019e-03, 5.1307e-03,  ..., 6.6757e-03,\n",
            "           4.7553e-03, 9.1919e-03],\n",
            "          [1.0999e-02, 8.0006e-03, 1.0989e-02,  ..., 7.6072e-03,\n",
            "           1.0973e-02, 9.4833e-03]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 1.1111e-03,  ..., 0.0000e+00,\n",
            "           1.5080e-03, 0.0000e+00],\n",
            "          [0.0000e+00, 1.8272e-04, 2.8776e-03,  ..., 7.6888e-04,\n",
            "           3.0376e-03, 1.3246e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 2.8805e-04],\n",
            "          ...,\n",
            "          [0.0000e+00, 7.5974e-04, 2.9872e-03,  ..., 1.5302e-03,\n",
            "           3.3993e-03, 1.5667e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 7.7945e-05,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 7.9567e-04],\n",
            "          [5.4519e-05, 0.0000e+00, 2.9779e-03,  ..., 0.0000e+00,\n",
            "           3.0243e-03, 0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[1.4548e-02, 1.1794e-02, 1.8026e-02,  ..., 1.1392e-02,\n",
            "           1.8105e-02, 1.1031e-02],\n",
            "          [9.1864e-03, 9.4629e-03, 1.1677e-02,  ..., 8.4867e-03,\n",
            "           1.0132e-02, 1.0185e-02],\n",
            "          [1.6676e-02, 1.2093e-02, 2.0421e-02,  ..., 1.1843e-02,\n",
            "           1.9838e-02, 1.1353e-02],\n",
            "          ...,\n",
            "          [8.6347e-03, 9.7761e-03, 1.1476e-02,  ..., 9.8545e-03,\n",
            "           1.0672e-02, 1.1142e-02],\n",
            "          [1.6574e-02, 1.1793e-02, 2.0491e-02,  ..., 1.1668e-02,\n",
            "           1.9582e-02, 1.1557e-02],\n",
            "          [1.1282e-02, 1.0831e-02, 1.2469e-02,  ..., 1.1493e-02,\n",
            "           1.2892e-02, 1.1958e-02]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>),)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {'skip_connection': tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[3.7424e-02, 5.7328e-02, 5.9981e-02,  ..., 4.8496e-02,\n",
            "           5.0257e-02, 4.5475e-02],\n",
            "          [4.1837e-02, 6.5709e-02, 6.4572e-02,  ..., 5.2826e-02,\n",
            "           5.7085e-02, 4.8095e-02],\n",
            "          [4.3037e-02, 7.3230e-02, 7.4771e-02,  ..., 6.0269e-02,\n",
            "           5.9538e-02, 4.9949e-02],\n",
            "          ...,\n",
            "          [4.5910e-02, 8.4429e-02, 8.6344e-02,  ..., 6.8269e-02,\n",
            "           6.5975e-02, 5.1534e-02],\n",
            "          [4.3252e-02, 7.2896e-02, 7.3493e-02,  ..., 5.8535e-02,\n",
            "           5.7096e-02, 4.5978e-02],\n",
            "          [3.8226e-02, 5.8252e-02, 5.8290e-02,  ..., 4.8835e-02,\n",
            "           4.8237e-02, 3.3215e-02]],\n",
            "\n",
            "         [[1.0170e-02, 1.8852e-02, 1.6926e-02,  ..., 1.4521e-02,\n",
            "           1.3836e-02, 9.5649e-03],\n",
            "          [4.5060e-03, 0.0000e+00, 0.0000e+00,  ..., 2.3803e-03,\n",
            "           2.3623e-03, 3.1167e-03],\n",
            "          [1.6007e-03, 0.0000e+00, 0.0000e+00,  ..., 3.9485e-03,\n",
            "           5.0061e-03, 3.1599e-03],\n",
            "          ...,\n",
            "          [5.9227e-04, 0.0000e+00, 0.0000e+00,  ..., 2.9096e-03,\n",
            "           4.6424e-03, 2.5288e-03],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 1.1491e-03],\n",
            "          [6.3728e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           3.3082e-03, 2.7107e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 8.8935e-03],\n",
            "          [0.0000e+00, 5.5319e-03, 9.6253e-03,  ..., 1.2417e-02,\n",
            "           1.4318e-02, 2.2602e-02],\n",
            "          [0.0000e+00, 7.0833e-03, 5.2045e-03,  ..., 8.8066e-03,\n",
            "           1.0756e-02, 1.8887e-02],\n",
            "          ...,\n",
            "          [0.0000e+00, 2.3062e-03, 5.1363e-03,  ..., 8.9744e-03,\n",
            "           1.1718e-02, 1.9685e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3414e-03,\n",
            "           1.1928e-02, 1.6431e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.6265e-03, 4.7896e-03]]],\n",
            "\n",
            "\n",
            "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[3.8017e-02, 5.7864e-02, 5.8703e-02,  ..., 5.7063e-02,\n",
            "           5.5233e-02, 4.5789e-02],\n",
            "          [4.1696e-02, 6.6280e-02, 6.2281e-02,  ..., 6.6749e-02,\n",
            "           6.3735e-02, 5.3221e-02],\n",
            "          [4.1769e-02, 7.1650e-02, 7.2896e-02,  ..., 7.6764e-02,\n",
            "           7.3694e-02, 5.6291e-02],\n",
            "          ...,\n",
            "          [4.5492e-02, 8.5447e-02, 8.7504e-02,  ..., 8.9515e-02,\n",
            "           8.5924e-02, 6.2569e-02],\n",
            "          [4.3323e-02, 7.3850e-02, 7.3080e-02,  ..., 7.4809e-02,\n",
            "           7.1714e-02, 5.6310e-02],\n",
            "          [3.8283e-02, 5.8513e-02, 5.8520e-02,  ..., 5.7730e-02,\n",
            "           5.6139e-02, 3.6637e-02]],\n",
            "\n",
            "         [[1.1349e-02, 1.8237e-02, 1.7504e-02,  ..., 1.3996e-02,\n",
            "           1.3361e-02, 5.8436e-03],\n",
            "          [5.6381e-03, 0.0000e+00, 0.0000e+00,  ..., 3.0325e-05,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.4730e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.6389e-03, 0.0000e+00],\n",
            "          ...,\n",
            "          [5.5460e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.4691e-03, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.1331e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           3.5329e-03, 3.2142e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 9.6289e-03],\n",
            "          [0.0000e+00, 5.4434e-03, 1.1444e-02,  ..., 7.5028e-03,\n",
            "           1.3013e-02, 2.3276e-02],\n",
            "          [0.0000e+00, 8.1313e-03, 7.1195e-03,  ..., 5.8391e-03,\n",
            "           1.0034e-02, 1.8296e-02],\n",
            "          ...,\n",
            "          [0.0000e+00, 3.1040e-03, 4.8398e-03,  ..., 3.6523e-03,\n",
            "           1.0771e-02, 2.1992e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.1144e-02, 1.9183e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.2780e-03, 5.5231e-03]]]], device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>)}\u001b[0m\n",
            "\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m<ipython-input-111-6b738f6f1def>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self=ConvTransposeBlock(\n",
            "  (conv1): Conv2d(256, 128, ...nel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "), x=tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ...e+00]]]], device='cuda:0', grad_fn=<CatBackward>), skip_connection=tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ... device='cuda:0',\n",
            "       grad_fn=<ReluBackward0>), last_layer=False)\u001b[0m\n",
            "\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_connection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     25\u001b[0m     \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mout2\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mF.relu\u001b[0m \u001b[0;34m= <function relu at 0x7f62a94ec840>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.conv2\u001b[0m \u001b[0;34m= Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mout1\u001b[0m \u001b[0;34m= tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0427, 0.0439, 0.0443,  ..., 0.0387, 0.0387, 0.0243],\n",
            "          [0.0494, 0.0515, 0.0508,  ..., 0.0430, 0.0426, 0.0265],\n",
            "          [0.0485, 0.0520, 0.0517,  ..., 0.0431, 0.0430, 0.0257],\n",
            "          ...,\n",
            "          [0.0473, 0.0536, 0.0517,  ..., 0.0438, 0.0435, 0.0255],\n",
            "          [0.0431, 0.0472, 0.0451,  ..., 0.0422, 0.0401, 0.0269],\n",
            "          [0.0323, 0.0350, 0.0327,  ..., 0.0329, 0.0330, 0.0278]],\n",
            "\n",
            "         [[0.0011, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0047],\n",
            "          [0.0032, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0075],\n",
            "          [0.0017, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0075],\n",
            "          ...,\n",
            "          [0.0043, 0.0013, 0.0012,  ..., 0.0000, 0.0017, 0.0085],\n",
            "          [0.0052, 0.0045, 0.0025,  ..., 0.0014, 0.0027, 0.0092],\n",
            "          [0.0100, 0.0133, 0.0137,  ..., 0.0088, 0.0089, 0.0126]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0069, 0.0118,  ..., 0.0058, 0.0038, 0.0000],\n",
            "          [0.0005, 0.0078, 0.0151,  ..., 0.0073, 0.0061, 0.0000],\n",
            "          ...,\n",
            "          [0.0025, 0.0131, 0.0196,  ..., 0.0106, 0.0086, 0.0000],\n",
            "          [0.0002, 0.0131, 0.0181,  ..., 0.0096, 0.0082, 0.0000],\n",
            "          [0.0000, 0.0035, 0.0066,  ..., 0.0013, 0.0017, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0010, 0.0077],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0005, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0032]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0427, 0.0432, 0.0437,  ..., 0.0410, 0.0404, 0.0242],\n",
            "          [0.0489, 0.0512, 0.0506,  ..., 0.0475, 0.0460, 0.0267],\n",
            "          [0.0485, 0.0520, 0.0517,  ..., 0.0499, 0.0478, 0.0264],\n",
            "          ...,\n",
            "          [0.0474, 0.0538, 0.0518,  ..., 0.0495, 0.0485, 0.0260],\n",
            "          [0.0431, 0.0476, 0.0451,  ..., 0.0462, 0.0445, 0.0271],\n",
            "          [0.0322, 0.0350, 0.0327,  ..., 0.0327, 0.0334, 0.0275]],\n",
            "\n",
            "         [[0.0012, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n",
            "          [0.0035, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0058],\n",
            "          [0.0022, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0057],\n",
            "          ...,\n",
            "          [0.0043, 0.0012, 0.0012,  ..., 0.0000, 0.0006, 0.0077],\n",
            "          [0.0052, 0.0046, 0.0028,  ..., 0.0012, 0.0017, 0.0089],\n",
            "          [0.0100, 0.0133, 0.0139,  ..., 0.0111, 0.0111, 0.0140]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0075, 0.0114,  ..., 0.0134, 0.0092, 0.0001],\n",
            "          [0.0007, 0.0079, 0.0155,  ..., 0.0159, 0.0136, 0.0027],\n",
            "          ...,\n",
            "          [0.0025, 0.0133, 0.0198,  ..., 0.0208, 0.0165, 0.0029],\n",
            "          [0.0005, 0.0131, 0.0183,  ..., 0.0176, 0.0154, 0.0028],\n",
            "          [0.0000, 0.0035, 0.0068,  ..., 0.0063, 0.0057, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0005, 0.0071],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0004, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0014]]]],\n",
            "       device='cuda:0', grad_fn=<ReluBackward0>)\u001b[0m\n",
            "\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     28\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input=tensor([[[[ 0.0146,  0.0082,  0.0074,  ...,  0.0...ice='cuda:0', grad_fn=<CudnnConvolutionBackward>), inplace=False)\u001b[0m\n",
            "\u001b[1;32m    941\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    942\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mglobal\u001b[0m \u001b[0;36mtorch.relu\u001b[0m \u001b[0;34m= <built-in method relu of type object at 0x7f62f4808b80>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[[[ 0.0146,  0.0082,  0.0074,  ...,  0.0088,  0.0102,  0.0167],\n",
            "          [ 0.0176,  0.0108,  0.0084,  ...,  0.0107,  0.0134,  0.0182],\n",
            "          [ 0.0165,  0.0089,  0.0078,  ...,  0.0092,  0.0131,  0.0179],\n",
            "          ...,\n",
            "          [ 0.0160,  0.0093,  0.0077,  ...,  0.0097,  0.0123,  0.0180],\n",
            "          [ 0.0180,  0.0120,  0.0123,  ...,  0.0129,  0.0158,  0.0193],\n",
            "          [ 0.0255,  0.0221,  0.0218,  ...,  0.0223,  0.0241,  0.0247]],\n",
            "\n",
            "         [[-0.0125, -0.0105, -0.0099,  ..., -0.0086, -0.0072, -0.0024],\n",
            "          [-0.0117, -0.0082, -0.0087,  ..., -0.0073, -0.0055, -0.0007],\n",
            "          [-0.0116, -0.0081, -0.0098,  ..., -0.0077, -0.0060, -0.0008],\n",
            "          ...,\n",
            "          [-0.0115, -0.0073, -0.0092,  ..., -0.0077, -0.0057, -0.0009],\n",
            "          [-0.0101, -0.0068, -0.0082,  ..., -0.0074, -0.0064, -0.0003],\n",
            "          [-0.0044, -0.0010, -0.0039,  ..., -0.0044, -0.0052, -0.0053]],\n",
            "\n",
            "         [[ 0.0251,  0.0198,  0.0189,  ...,  0.0172,  0.0180,  0.0146],\n",
            "          [ 0.0207,  0.0103,  0.0085,  ...,  0.0071,  0.0088,  0.0085],\n",
            "          [ 0.0216,  0.0095,  0.0063,  ...,  0.0046,  0.0066,  0.0058],\n",
            "          ...,\n",
            "          [ 0.0217,  0.0094,  0.0052,  ...,  0.0040,  0.0053,  0.0050],\n",
            "          [ 0.0195,  0.0069,  0.0026,  ...,  0.0024,  0.0029,  0.0041],\n",
            "          [ 0.0137,  0.0030, -0.0002,  ..., -0.0009,  0.0008,  0.0033]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0011, -0.0015, -0.0033,  ..., -0.0021, -0.0008,  0.0030],\n",
            "          [-0.0080, -0.0117, -0.0145,  ..., -0.0136, -0.0105, -0.0031],\n",
            "          [-0.0086, -0.0141, -0.0173,  ..., -0.0157, -0.0127, -0.0042],\n",
            "          ...,\n",
            "          [-0.0100, -0.0164, -0.0189,  ..., -0.0175, -0.0127, -0.0048],\n",
            "          [-0.0091, -0.0150, -0.0178,  ..., -0.0150, -0.0125, -0.0042],\n",
            "          [-0.0065, -0.0121, -0.0140,  ..., -0.0129, -0.0094, -0.0030]],\n",
            "\n",
            "         [[-0.0266, -0.0247, -0.0237,  ..., -0.0236, -0.0229, -0.0231],\n",
            "          [-0.0269, -0.0263, -0.0245,  ..., -0.0241, -0.0238, -0.0211],\n",
            "          [-0.0272, -0.0255, -0.0242,  ..., -0.0239, -0.0227, -0.0198],\n",
            "          ...,\n",
            "          [-0.0269, -0.0267, -0.0243,  ..., -0.0236, -0.0228, -0.0194],\n",
            "          [-0.0257, -0.0261, -0.0233,  ..., -0.0231, -0.0228, -0.0198],\n",
            "          [-0.0240, -0.0243, -0.0226,  ..., -0.0226, -0.0216, -0.0191]],\n",
            "\n",
            "         [[-0.0112, -0.0111, -0.0115,  ..., -0.0111, -0.0114, -0.0083],\n",
            "          [-0.0148, -0.0149, -0.0141,  ..., -0.0146, -0.0135, -0.0081],\n",
            "          [-0.0174, -0.0167, -0.0163,  ..., -0.0158, -0.0154, -0.0087],\n",
            "          ...,\n",
            "          [-0.0173, -0.0168, -0.0156,  ..., -0.0163, -0.0150, -0.0082],\n",
            "          [-0.0166, -0.0158, -0.0151,  ..., -0.0148, -0.0148, -0.0083],\n",
            "          [-0.0149, -0.0114, -0.0110,  ..., -0.0108, -0.0101, -0.0051]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0146,  0.0082,  0.0075,  ...,  0.0081,  0.0103,  0.0170],\n",
            "          [ 0.0175,  0.0108,  0.0085,  ...,  0.0094,  0.0128,  0.0185],\n",
            "          [ 0.0167,  0.0089,  0.0078,  ...,  0.0077,  0.0123,  0.0180],\n",
            "          ...,\n",
            "          [ 0.0160,  0.0092,  0.0078,  ...,  0.0085,  0.0116,  0.0179],\n",
            "          [ 0.0180,  0.0119,  0.0123,  ...,  0.0123,  0.0156,  0.0194],\n",
            "          [ 0.0255,  0.0221,  0.0217,  ...,  0.0214,  0.0234,  0.0244]],\n",
            "\n",
            "         [[-0.0125, -0.0104, -0.0097,  ..., -0.0090, -0.0074, -0.0024],\n",
            "          [-0.0117, -0.0081, -0.0085,  ..., -0.0079, -0.0059, -0.0007],\n",
            "          [-0.0115, -0.0078, -0.0096,  ..., -0.0093, -0.0069, -0.0010],\n",
            "          ...,\n",
            "          [-0.0115, -0.0074, -0.0093,  ..., -0.0089, -0.0063, -0.0013],\n",
            "          [-0.0101, -0.0068, -0.0083,  ..., -0.0087, -0.0077, -0.0007],\n",
            "          [-0.0044, -0.0010, -0.0039,  ..., -0.0046, -0.0056, -0.0057]],\n",
            "\n",
            "         [[ 0.0252,  0.0198,  0.0187,  ...,  0.0175,  0.0182,  0.0143],\n",
            "          [ 0.0208,  0.0104,  0.0084,  ...,  0.0068,  0.0081,  0.0076],\n",
            "          [ 0.0217,  0.0094,  0.0059,  ...,  0.0042,  0.0058,  0.0044],\n",
            "          ...,\n",
            "          [ 0.0218,  0.0094,  0.0052,  ...,  0.0035,  0.0043,  0.0031],\n",
            "          [ 0.0195,  0.0068,  0.0026,  ...,  0.0016,  0.0021,  0.0026],\n",
            "          [ 0.0138,  0.0030, -0.0002,  ..., -0.0021, -0.0005,  0.0019]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0011, -0.0014, -0.0031,  ..., -0.0027, -0.0013,  0.0030],\n",
            "          [-0.0082, -0.0119, -0.0147,  ..., -0.0154, -0.0119, -0.0035],\n",
            "          [-0.0088, -0.0143, -0.0170,  ..., -0.0178, -0.0146, -0.0049],\n",
            "          ...,\n",
            "          [-0.0100, -0.0165, -0.0189,  ..., -0.0210, -0.0152, -0.0063],\n",
            "          [-0.0092, -0.0150, -0.0178,  ..., -0.0178, -0.0147, -0.0052],\n",
            "          [-0.0065, -0.0122, -0.0140,  ..., -0.0151, -0.0110, -0.0039]],\n",
            "\n",
            "         [[-0.0266, -0.0246, -0.0238,  ..., -0.0227, -0.0223, -0.0227],\n",
            "          [-0.0270, -0.0264, -0.0247,  ..., -0.0227, -0.0227, -0.0204],\n",
            "          [-0.0273, -0.0257, -0.0243,  ..., -0.0216, -0.0208, -0.0184],\n",
            "          ...,\n",
            "          [-0.0269, -0.0268, -0.0243,  ..., -0.0221, -0.0210, -0.0177],\n",
            "          [-0.0257, -0.0261, -0.0233,  ..., -0.0219, -0.0210, -0.0183],\n",
            "          [-0.0240, -0.0243, -0.0226,  ..., -0.0222, -0.0210, -0.0181]],\n",
            "\n",
            "         [[-0.0111, -0.0111, -0.0113,  ..., -0.0117, -0.0118, -0.0084],\n",
            "          [-0.0147, -0.0149, -0.0139,  ..., -0.0146, -0.0134, -0.0082],\n",
            "          [-0.0173, -0.0164, -0.0157,  ..., -0.0157, -0.0148, -0.0084],\n",
            "          ...,\n",
            "          [-0.0173, -0.0168, -0.0156,  ..., -0.0159, -0.0141, -0.0075],\n",
            "          [-0.0167, -0.0158, -0.0151,  ..., -0.0142, -0.0140, -0.0074],\n",
            "          [-0.0149, -0.0114, -0.0111,  ..., -0.0108, -0.0099, -0.0046]]]],\n",
            "       device='cuda:0', grad_fn=<CudnnConvolutionBackward>)\u001b[0m\n",
            "\u001b[1;32m    944\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 11.17 GiB total capacity; 10.76 GiB already allocated; 39.81 MiB free; 36.77 MiB cached)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoJ1TutGwfMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CZ062Jv1jIIu"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 2\n",
        "\n",
        "Plot performance over time\n",
        "\n",
        "Please generate a plot that shows loss on the training set as a function of training time. Make sure your axes are labeled!\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Plot training loss as function of training time (not Epochs)\n",
        "\n",
        "**DONE:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mTg1jyIsYVZN",
        "colab": {}
      },
      "source": [
        "# Your plotting code here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S4s92S2_jQOG"
      },
      "source": [
        "___\n",
        "\n",
        "### Part 3\n",
        "\n",
        "Generate a prediction on the pos_test_000072.png image\n",
        "\n",
        "Calculate the output of your trained network on the pos_test_000072.png image,\n",
        "then make a hard decision (cancerous/not-cancerous) for each pixel.\n",
        "The resulting image should be black-and-white, where white pixels represent things\n",
        "you think are probably cancerous.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "**NOTE:**\n",
        "\n",
        "Guessing that the pixel is not cancerous every single time will give you an accuracy of ~ 85%.\n",
        "Your trained network should be able to do better than that (but you will not be graded on accuracy).\n",
        "This is the result I got after 1 hour or training.\n",
        "\n",
        "![](http://liftothers.org/dokuwiki/lib/exe/fetch.php?w=400&tok=d23e0b&media=cs501r_f2016:training_accuracy.png)\n",
        "![](http://liftothers.org/dokuwiki/lib/exe/fetch.php?w=400&tok=bb8e3c&media=cs501r_f2016:training_loss.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XXfG3wClh8an",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "# Code for testing prediction on an image\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}